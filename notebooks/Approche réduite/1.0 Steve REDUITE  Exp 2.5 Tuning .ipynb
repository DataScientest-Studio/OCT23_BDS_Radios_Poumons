{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47e8461d-786c-4d6f-818a-1ca91a15a73e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# Input: PROFIL: Reduction de dimmension    \n",
    "# Modele: TUNING Hyperparmètre d'un modele type LeNet 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d79e45d1-66c5-4176-9411-7b9e2685c41d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-02 16:10:56.901821: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from contextlib import redirect_stdout\n",
    "import keras_tuner as kt\n",
    "\n",
    "from sklearn import preprocessing, model_selection\n",
    "from sklearn import metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9926d6-fac2-43bf-a641-ebaeab72b7b3",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2c028e4-0005-4f87-8dc6-41ec07938c10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Acquisition\n",
    "df_train = pd.read_json('Train_Intensite_H.json')\n",
    "df_train['Intensite'] = df_train['Intensite'].apply(lambda x: np.array(x)/(np.array(x).max())).tolist()\n",
    "df_test = pd.read_json('Test_Intensite_H.json')\n",
    "df_test['Intensite'] = df_test['Intensite'].apply(lambda x: np.array(x)/(np.array(x).max())).tolist()\n",
    "\n",
    "#Preprocessing\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "x_train_list = [ scaler.fit_transform(np.asarray(i).reshape(-1, 1)) for i in df_train['Intensite']]\n",
    "y_train_list = [i for i in df_train['Diagnostic']]\n",
    "x_test_list = [ scaler.fit_transform(np.asarray(i).reshape(-1, 1)) for i in df_test['Intensite']]\n",
    "y_test_list = [i for i in df_test['Diagnostic']]\n",
    "\n",
    "#Création des jeu d'entrainement, de validation et de Test\n",
    "x_train, x_val, y_train, y_val = model_selection.train_test_split(x_train_list, y_train_list, test_size=0.2, random_state=42, shuffle=True)\n",
    "x_train = np.asarray(x_train).astype(np.float32).reshape(-1, 256, 1)\n",
    "y_train = np.asarray(y_train).astype(np.float32).reshape(-1, 1)\n",
    "x_val = np.asarray(x_val).astype(np.float32).reshape(-1, 256, 1)\n",
    "y_val = np.asarray(y_val).astype(np.float32).reshape(-1, 1)\n",
    "x_test = np.asarray(x_test_list).astype(np.float32).reshape(-1, 256, 1)\n",
    "y_test = np.asarray(y_test_list).astype(np.float32).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81822dd8-e5a4-4ce9-a8c3-b909484d0f58",
   "metadata": {
    "tags": []
   },
   "source": [
    "# SET UP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2b7cb4-a184-4f59-9315-ad7e149d1b2c",
   "metadata": {},
   "source": [
    "### Define simple function to plot all the metrics present in a keras.callbacks.History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29042bcf-430d-4253-b441-58cef78edf01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "  \n",
    "def plot_history_metrics(history: keras.callbacks.History):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    \n",
    "    fig = plt.figure(figsize=(12,6))\n",
    "    ax1 = fig.add_subplot(121)\n",
    "\n",
    "    ax1.plot(acc, label='Training Accuracy')\n",
    "    ax1.plot(val_acc, label='Validation Accuracy')\n",
    "    ax1.legend(loc='lower right')\n",
    "    ax1.set_title('Training and Validation Accuracy')\n",
    "\n",
    "    ax2 = fig.add_subplot(122)\n",
    "    ax2.plot(loss, label='Training Loss')\n",
    "    ax2.plot(val_loss, label='Validation Loss')\n",
    "    ax2.legend(loc='upper right')\n",
    "    ax2.set_title('Training and Validation Loss')\n",
    "    plt.show()\n",
    "    \n",
    "    fig.savefig(\"Training and Validation.png\")\n",
    "    plt.close(fig)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952e8d49-b667-4cc8-8731-09cf5d9f8c27",
   "metadata": {},
   "source": [
    "### build_model function to generate 1D LeNet Like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2083e4eb-8c72-4e07-bef5-aecbe051ae03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "\n",
    "    # Model Variables\n",
    "    loss = keras.losses.BinaryCrossentropy()\n",
    "    thresh = hp.Float(\"thresh\", min_value=0.3, max_value=0.45, step= 0.05)\n",
    "    l_rate = hp.Float(\"lr\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
    "    adam = tf.keras.optimizers.Adam(learning_rate= l_rate)\n",
    "    metric = tf.keras.metrics.BinaryAccuracy(name ='accuracy', threshold= thresh)\n",
    "\n",
    "\n",
    "    # Model architecture    \n",
    "    input_layer = keras.Input(shape=(256, 1))\n",
    "\n",
    "    x = layers.Conv1D(filters=256, kernel_size=3, strides=2, activation=hp.Choice(f\"activation_c0\", [\"relu\", \"tanh\"]), padding=\"same\")(input_layer)\n",
    "\n",
    "    for i in range (hp.Int(\"num_conv_layer\", 0, 5, step=1)):\n",
    "        x = layers.Conv1D( filters=hp.Int(\"filter_conv_0\", 32, 1024, sampling='log', step=2), \n",
    "                          kernel_size=5, strides=2, activation=hp.Choice(f\"activation_c{i+1}\", [\"relu\", \"tanh\"]), padding=\"same\")(x)\n",
    "    \n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Flatten()(x)\n",
    "\n",
    "    x = layers.Dense(256, activation=hp.Choice(f\"activation_d0\", [\"relu\", \"tanh\"]), kernel_regularizer=keras.regularizers.L2())(x)\n",
    "        \n",
    "    for i in range (hp.Int(\"num_hidden_layer\", 1, 5, step=1)):\n",
    "        if hp.Boolean(f\"dropout_{i}\"):\n",
    "            x = layers.Dropout(0.2)(x)\n",
    "\n",
    "        x = layers.Dense(units=hp.Int(f\"units_{i+1}\", min_value=32, max_value=512, step=32),\n",
    "                         activation=hp.Choice(f\"activation_d{i+1}\", [\"relu\", \"tanh\"]),\n",
    "                         kernel_regularizer=keras.regularizers.L2())(x)\n",
    "\n",
    "    output_layer = layers.Dense(1, activation=\"relu\")(x)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    # Modele compilation\n",
    "    model.compile(optimizer=adam, loss=loss, metrics=metric)\n",
    "    \n",
    "    \n",
    "    return model \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a12348-359e-4f6e-90f4-8c93ae93a893",
   "metadata": {},
   "source": [
    "### Instanciate main variables: callbacks, optimizer, loss , metrics, epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95496639-b377-4b0a-a3f8-4802fbdf342d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_NAME = \"1D-LeNet-like Tuning\"\n",
    "\n",
    "\n",
    "PATH_DIR = \"./Tuning\"\n",
    "\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\"best_model.h5\", save_best_only=True, monitor=\"val_accuracy\"),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau( monitor=\"val_accuracy\", factor=0.2, patience=10, min_lr=0.000001),\n",
    "    tf.keras.callbacks.EarlyStopping( monitor=\"val_accuracy\", patience=8, verbose=1, mode=\"auto\", restore_best_weights=True, start_from_epoch=10)]\n",
    "\n",
    "\n",
    "hp = kt.HyperParameters()\n",
    "model = build_model(hp)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6da71c-6390-4670-be06-74a0a33f9fd4",
   "metadata": {},
   "source": [
    "Fine Tuning des hyper paramétres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f2e04b3-5304-405b-a16f-80e452c3db6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 46 Complete [00h 04m 14s]\n",
      "val_accuracy: 0.6811145544052124\n",
      "\n",
      "Best val_accuracy So Far: 0.8250774145126343\n",
      "Total elapsed time: 02h 59m 42s\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.Hyperband(\n",
    "    hypermodel=build_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_epochs=15,\n",
    "    factor=2,\n",
    "    directory=PATH_DIR,\n",
    "    overwrite=True,\n",
    "    project_name=PROJECT_NAME)\n",
    "\n",
    "\n",
    "\n",
    "tuner.search(x_train, y_train, epochs=50, validation_data=(x_val, y_val), callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffde96d3-4e62-4033-9cde-d793e8594bf7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### sauvegarde de la meilleures architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e10b18-a510-4dee-8616-186384a8d4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(tunerSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbe2571e-1490-4523-aba2-ae662251448a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "with open(PATH_DIR + '/tuning.txt', 'w') as f:\n",
    "    with redirect_stdout(f):\n",
    "        print('BEST MODEL-------------')\n",
    "        print('-----------------------')\n",
    "        tuner.results_summary(1)\n",
    "        print('SPACE SEARCH-------------')\n",
    "        print('-----------------------')\n",
    "        tuner.search_space_summary()\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73964d98-0bb9-46bc-9b81-acb546140951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "162/162 [==============================] - 14s 74ms/step - loss: 10.0181 - accuracy: 0.6431 - val_loss: 9.3238 - val_accuracy: 0.5015\n",
      "Epoch 2/250\n",
      "162/162 [==============================] - 12s 72ms/step - loss: 7.6486 - accuracy: 0.6780 - val_loss: 7.3172 - val_accuracy: 0.5015\n",
      "Epoch 3/250\n",
      "162/162 [==============================] - 12s 74ms/step - loss: 6.2202 - accuracy: 0.6483 - val_loss: 5.7798 - val_accuracy: 0.7337\n",
      "Epoch 4/250\n",
      "162/162 [==============================] - 12s 72ms/step - loss: 5.1690 - accuracy: 0.7361 - val_loss: 4.7973 - val_accuracy: 0.7376\n",
      "Epoch 5/250\n",
      "162/162 [==============================] - 12s 73ms/step - loss: 4.4511 - accuracy: 0.7459 - val_loss: 4.1085 - val_accuracy: 0.8127\n",
      "Epoch 6/250\n",
      "162/162 [==============================] - 12s 72ms/step - loss: 4.0041 - accuracy: 0.6867 - val_loss: 3.6857 - val_accuracy: 0.7005\n",
      "Epoch 7/250\n",
      "162/162 [==============================] - 12s 72ms/step - loss: 3.5790 - accuracy: 0.7483 - val_loss: 3.7245 - val_accuracy: 0.7485\n",
      "Epoch 8/250\n",
      "162/162 [==============================] - 12s 75ms/step - loss: 3.2674 - accuracy: 0.7285 - val_loss: 3.0426 - val_accuracy: 0.7190\n",
      "Epoch 9/250\n",
      "162/162 [==============================] - 12s 74ms/step - loss: 2.9586 - accuracy: 0.7438 - val_loss: 2.8035 - val_accuracy: 0.7988\n",
      "Epoch 10/250\n",
      "162/162 [==============================] - 12s 74ms/step - loss: 2.7748 - accuracy: 0.7386 - val_loss: 2.6907 - val_accuracy: 0.6803\n",
      "Epoch 11/250\n",
      "162/162 [==============================] - 12s 73ms/step - loss: 2.5181 - accuracy: 0.7343 - val_loss: 2.5302 - val_accuracy: 0.6207\n",
      "Epoch 12/250\n",
      "162/162 [==============================] - 12s 73ms/step - loss: 2.3145 - accuracy: 0.7620 - val_loss: 2.3680 - val_accuracy: 0.7206\n",
      "Epoch 13/250\n",
      "162/162 [==============================] - 12s 75ms/step - loss: 2.1711 - accuracy: 0.7603 - val_loss: 2.0675 - val_accuracy: 0.7848\n",
      "Epoch 14/250\n",
      "162/162 [==============================] - 14s 85ms/step - loss: 2.1400 - accuracy: 0.6907 - val_loss: 2.0571 - val_accuracy: 0.6664\n",
      "Epoch 15/250\n",
      "162/162 [==============================] - 12s 77ms/step - loss: 1.9815 - accuracy: 0.6840 - val_loss: 1.8930 - val_accuracy: 0.7701\n",
      "Epoch 16/250\n",
      "162/162 [==============================] - 12s 73ms/step - loss: 1.7837 - accuracy: 0.7637 - val_loss: 1.7268 - val_accuracy: 0.8050\n",
      "Epoch 17/250\n",
      "162/162 [==============================] - 12s 73ms/step - loss: 1.6724 - accuracy: 0.7713 - val_loss: 1.6185 - val_accuracy: 0.8057\n",
      "Epoch 18/250\n",
      "162/162 [==============================] - 12s 74ms/step - loss: 1.5821 - accuracy: 0.7663 - val_loss: 1.6171 - val_accuracy: 0.8003\n",
      "Epoch 19/250\n",
      "162/162 [==============================] - 14s 88ms/step - loss: 1.5723 - accuracy: 0.7306 - val_loss: 2.0185 - val_accuracy: 0.7190\n",
      "Epoch 20/250\n",
      "162/162 [==============================] - 13s 78ms/step - loss: 1.5534 - accuracy: 0.6917 - val_loss: 1.6433 - val_accuracy: 0.6594\n",
      "Epoch 21/250\n",
      "162/162 [==============================] - 12s 73ms/step - loss: 1.4785 - accuracy: 0.6729 - val_loss: 1.3819 - val_accuracy: 0.7307\n",
      "Epoch 22/250\n",
      "162/162 [==============================] - 12s 75ms/step - loss: 1.3473 - accuracy: 0.7535 - val_loss: 1.2985 - val_accuracy: 0.7848\n",
      "Epoch 23/250\n",
      "162/162 [==============================] - 12s 73ms/step - loss: 1.2651 - accuracy: 0.7742 - val_loss: 1.2731 - val_accuracy: 0.7454\n",
      "Epoch 24/250\n",
      "162/162 [==============================] - 12s 74ms/step - loss: 1.2102 - accuracy: 0.7845 - val_loss: 1.3554 - val_accuracy: 0.7949\n",
      "Epoch 25/250\n",
      "162/162 [==============================] - 12s 74ms/step - loss: 1.1552 - accuracy: 0.7796 - val_loss: 1.1300 - val_accuracy: 0.7895\n",
      "Epoch 26/250\n",
      "162/162 [==============================] - 12s 73ms/step - loss: 1.0819 - accuracy: 0.7930 - val_loss: 1.0779 - val_accuracy: 0.8096\n",
      "Epoch 27/250\n",
      "162/162 [==============================] - 12s 74ms/step - loss: 1.0405 - accuracy: 0.7980 - val_loss: 1.0528 - val_accuracy: 0.7895\n",
      "Epoch 28/250\n",
      "162/162 [==============================] - 12s 75ms/step - loss: 1.2038 - accuracy: 0.6538 - val_loss: 1.1686 - val_accuracy: 0.7438\n",
      "Epoch 29/250\n",
      "162/162 [==============================] - 13s 79ms/step - loss: 1.0266 - accuracy: 0.7390 - val_loss: 0.9480 - val_accuracy: 0.8096\n",
      "Epoch 30/250\n",
      "162/162 [==============================] - 13s 79ms/step - loss: 0.9603 - accuracy: 0.7821 - val_loss: 0.9528 - val_accuracy: 0.7260\n",
      "Epoch 31/250\n",
      "162/162 [==============================] - 15s 91ms/step - loss: 1.0125 - accuracy: 0.7192 - val_loss: 0.9617 - val_accuracy: 0.7384\n",
      "Epoch 32/250\n",
      "162/162 [==============================] - 16s 99ms/step - loss: 0.8902 - accuracy: 0.7752 - val_loss: 0.8669 - val_accuracy: 0.8243\n",
      "Epoch 33/250\n",
      "162/162 [==============================] - 13s 81ms/step - loss: 0.9132 - accuracy: 0.7703 - val_loss: 0.9230 - val_accuracy: 0.6865\n",
      "Epoch 34/250\n",
      "162/162 [==============================] - 12s 77ms/step - loss: 0.8759 - accuracy: 0.7475 - val_loss: 0.8816 - val_accuracy: 0.7988\n",
      "Epoch 35/250\n",
      "162/162 [==============================] - 12s 73ms/step - loss: 0.8352 - accuracy: 0.7746 - val_loss: 0.8207 - val_accuracy: 0.7926\n",
      "Epoch 36/250\n",
      "162/162 [==============================] - 12s 74ms/step - loss: 0.8234 - accuracy: 0.7676 - val_loss: 0.7883 - val_accuracy: 0.7817\n",
      "Epoch 37/250\n",
      "162/162 [==============================] - 12s 75ms/step - loss: 0.7834 - accuracy: 0.7851 - val_loss: 0.7373 - val_accuracy: 0.8297\n",
      "Epoch 38/250\n",
      "162/162 [==============================] - 14s 86ms/step - loss: 0.7433 - accuracy: 0.8005 - val_loss: 0.7191 - val_accuracy: 0.7910\n",
      "Epoch 39/250\n",
      "162/162 [==============================] - 13s 80ms/step - loss: 0.7218 - accuracy: 0.8067 - val_loss: 0.7569 - val_accuracy: 0.7515\n",
      "Epoch 40/250\n",
      "162/162 [==============================] - 12s 73ms/step - loss: 0.7205 - accuracy: 0.7998 - val_loss: 0.7702 - val_accuracy: 0.7585\n",
      "Epoch 41/250\n",
      "162/162 [==============================] - 12s 75ms/step - loss: 0.6770 - accuracy: 0.8031 - val_loss: 0.6922 - val_accuracy: 0.8274\n",
      "Epoch 42/250\n",
      "162/162 [==============================] - 12s 73ms/step - loss: 0.6637 - accuracy: 0.8102 - val_loss: 0.7577 - val_accuracy: 0.8166\n",
      "Epoch 43/250\n",
      "162/162 [==============================] - 12s 74ms/step - loss: 0.6667 - accuracy: 0.7996 - val_loss: 0.6787 - val_accuracy: 0.7616\n",
      "Epoch 44/250\n",
      "162/162 [==============================] - 13s 79ms/step - loss: 0.6234 - accuracy: 0.8079 - val_loss: 0.6266 - val_accuracy: 0.8266\n",
      "Epoch 45/250\n",
      "162/162 [==============================] - 12s 73ms/step - loss: 0.6084 - accuracy: 0.8085 - val_loss: 0.6285 - val_accuracy: 0.8181\n",
      "Epoch 46/250\n",
      "162/162 [==============================] - 12s 73ms/step - loss: 0.6018 - accuracy: 0.8040 - val_loss: 0.6282 - val_accuracy: 0.8320\n",
      "Epoch 47/250\n",
      "162/162 [==============================] - 12s 75ms/step - loss: 0.6613 - accuracy: 0.7645 - val_loss: 0.5830 - val_accuracy: 0.8111\n",
      "Epoch 48/250\n",
      "162/162 [==============================] - 11s 70ms/step - loss: 0.5807 - accuracy: 0.8058 - val_loss: 0.5612 - val_accuracy: 0.8142\n",
      "Epoch 49/250\n",
      "162/162 [==============================] - 13s 82ms/step - loss: 0.5827 - accuracy: 0.8089 - val_loss: 0.5843 - val_accuracy: 0.8073\n",
      "Epoch 50/250\n",
      "162/162 [==============================] - 12s 76ms/step - loss: 0.5434 - accuracy: 0.8133 - val_loss: 0.6054 - val_accuracy: 0.8189\n",
      "Epoch 51/250\n",
      "162/162 [==============================] - 12s 77ms/step - loss: 0.5667 - accuracy: 0.8002 - val_loss: 0.5557 - val_accuracy: 0.7817\n",
      "Epoch 52/250\n",
      "162/162 [==============================] - 14s 88ms/step - loss: 0.5344 - accuracy: 0.8095 - val_loss: 0.5689 - val_accuracy: 0.8197\n",
      "Epoch 53/250\n",
      "162/162 [==============================] - 13s 82ms/step - loss: 0.5186 - accuracy: 0.8125 - val_loss: 0.5431 - val_accuracy: 0.7693\n",
      "Epoch 54/250\n",
      "162/162 [==============================] - 12s 76ms/step - loss: 0.5079 - accuracy: 0.8147 - val_loss: 0.5341 - val_accuracy: 0.8104\n",
      "Epoch 55/250\n",
      "162/162 [==============================] - 12s 74ms/step - loss: 0.5038 - accuracy: 0.8234 - val_loss: 0.5232 - val_accuracy: 0.7988\n",
      "Epoch 56/250\n",
      "162/162 [==============================] - 12s 75ms/step - loss: 0.4800 - accuracy: 0.8168 - val_loss: 0.6166 - val_accuracy: 0.7539\n",
      "Epoch 57/250\n",
      "162/162 [==============================] - 12s 74ms/step - loss: 0.4846 - accuracy: 0.8122 - val_loss: 0.5308 - val_accuracy: 0.8197\n",
      "Epoch 58/250\n",
      "162/162 [==============================] - 12s 73ms/step - loss: 0.4969 - accuracy: 0.8220 - val_loss: 0.5213 - val_accuracy: 0.8166\n",
      "Epoch 59/250\n",
      "162/162 [==============================] - 11s 69ms/step - loss: 0.5251 - accuracy: 0.7920 - val_loss: 1.0411 - val_accuracy: 0.6819\n",
      "Epoch 60/250\n",
      "162/162 [==============================] - 12s 74ms/step - loss: 0.5821 - accuracy: 0.7473 - val_loss: 0.5789 - val_accuracy: 0.7229\n",
      "Epoch 61/250\n",
      "162/162 [==============================] - 12s 75ms/step - loss: 0.5182 - accuracy: 0.7974 - val_loss: 0.6124 - val_accuracy: 0.8042\n",
      "Epoch 62/250\n",
      "162/162 [==============================] - 12s 75ms/step - loss: 0.4857 - accuracy: 0.8017 - val_loss: 0.4951 - val_accuracy: 0.8050\n",
      "Epoch 63/250\n",
      "162/162 [==============================] - 13s 79ms/step - loss: 0.4662 - accuracy: 0.8162 - val_loss: 0.4921 - val_accuracy: 0.8150\n",
      "Epoch 64/250\n",
      "162/162 [==============================] - 14s 85ms/step - loss: 0.4840 - accuracy: 0.8199 - val_loss: 0.5283 - val_accuracy: 0.8142\n",
      "Epoch 65/250\n",
      "162/162 [==============================] - 13s 79ms/step - loss: 0.4678 - accuracy: 0.8195 - val_loss: 0.5848 - val_accuracy: 0.7755\n",
      "Epoch 66/250\n",
      "162/162 [==============================] - 12s 76ms/step - loss: 0.4832 - accuracy: 0.8044 - val_loss: 0.4839 - val_accuracy: 0.8189\n",
      "Epoch 67/250\n",
      "162/162 [==============================] - 12s 74ms/step - loss: 0.4500 - accuracy: 0.8203 - val_loss: 0.5026 - val_accuracy: 0.7299\n",
      "Epoch 68/250\n",
      "162/162 [==============================] - 13s 78ms/step - loss: 0.4337 - accuracy: 0.8265 - val_loss: 0.4808 - val_accuracy: 0.8034\n",
      "Epoch 69/250\n",
      "162/162 [==============================] - 12s 75ms/step - loss: 0.4421 - accuracy: 0.8242 - val_loss: 0.4612 - val_accuracy: 0.8042\n",
      "Epoch 70/250\n",
      "162/162 [==============================] - 12s 76ms/step - loss: 0.4252 - accuracy: 0.8304 - val_loss: 0.4929 - val_accuracy: 0.8204\n",
      "Epoch 71/250\n",
      "162/162 [==============================] - 12s 77ms/step - loss: 0.4122 - accuracy: 0.8304 - val_loss: 0.4569 - val_accuracy: 0.8197\n",
      "Epoch 72/250\n",
      "162/162 [==============================] - 12s 74ms/step - loss: 0.4109 - accuracy: 0.8300 - val_loss: 0.4937 - val_accuracy: 0.8259\n",
      "Epoch 73/250\n",
      "162/162 [==============================] - 12s 74ms/step - loss: 0.3965 - accuracy: 0.8381 - val_loss: 0.5492 - val_accuracy: 0.8142\n",
      "Epoch 74/250\n",
      "162/162 [==============================] - 14s 88ms/step - loss: 0.4011 - accuracy: 0.8385 - val_loss: 0.4540 - val_accuracy: 0.8220\n",
      "Epoch 75/250\n",
      "162/162 [==============================] - 13s 79ms/step - loss: 0.4385 - accuracy: 0.8178 - val_loss: 0.5422 - val_accuracy: 0.8266\n",
      "Epoch 76/250\n",
      "162/162 [==============================] - 12s 75ms/step - loss: 0.4324 - accuracy: 0.8360 - val_loss: 0.6704 - val_accuracy: 0.6153\n",
      "Epoch 77/250\n",
      "162/162 [==============================] - 12s 75ms/step - loss: 0.4781 - accuracy: 0.8180 - val_loss: 0.6923 - val_accuracy: 0.5774\n",
      "Epoch 78/250\n",
      "162/162 [==============================] - 12s 76ms/step - loss: 0.6337 - accuracy: 0.6780 - val_loss: 0.5661 - val_accuracy: 0.8158\n",
      "Epoch 79/250\n",
      "162/162 [==============================] - 14s 89ms/step - loss: 0.6666 - accuracy: 0.6576 - val_loss: 0.6719 - val_accuracy: 0.6053\n",
      "Epoch 80/250\n",
      "162/162 [==============================] - 13s 78ms/step - loss: 0.6135 - accuracy: 0.6803 - val_loss: 0.6084 - val_accuracy: 0.7175\n",
      "Epoch 81/250\n",
      "162/162 [==============================] - 12s 76ms/step - loss: 0.5905 - accuracy: 0.7239 - val_loss: 0.5955 - val_accuracy: 0.7399\n",
      "Epoch 82/250\n",
      "162/162 [==============================] - 13s 82ms/step - loss: 0.5396 - accuracy: 0.7378 - val_loss: 0.6159 - val_accuracy: 0.7237\n",
      "Epoch 83/250\n",
      "162/162 [==============================] - 13s 81ms/step - loss: 0.5728 - accuracy: 0.7328 - val_loss: 0.5854 - val_accuracy: 0.7299\n",
      "Epoch 84/250\n",
      "162/162 [==============================] - 12s 74ms/step - loss: 0.5674 - accuracy: 0.7364 - val_loss: 0.5906 - val_accuracy: 0.7268\n",
      "Epoch 85/250\n",
      "162/162 [==============================] - 14s 89ms/step - loss: 0.5426 - accuracy: 0.7492 - val_loss: 0.5459 - val_accuracy: 0.7949\n",
      "Epoch 86/250\n",
      "162/162 [==============================] - 13s 80ms/step - loss: 0.6244 - accuracy: 0.7254 - val_loss: 0.6047 - val_accuracy: 0.7051\n",
      "Epoch 87/250\n",
      "162/162 [==============================] - 12s 72ms/step - loss: 0.5689 - accuracy: 0.7448 - val_loss: 0.5583 - val_accuracy: 0.7601\n",
      "Epoch 88/250\n",
      "162/162 [==============================] - 11s 71ms/step - loss: 0.5520 - accuracy: 0.7723 - val_loss: 0.5764 - val_accuracy: 0.7562\n",
      "Epoch 89/250\n",
      "162/162 [==============================] - 12s 77ms/step - loss: 0.6588 - accuracy: 0.7241 - val_loss: 0.6342 - val_accuracy: 0.7198\n",
      "Epoch 90/250\n",
      "162/162 [==============================] - 12s 72ms/step - loss: 0.5898 - accuracy: 0.7428 - val_loss: 0.6424 - val_accuracy: 0.7539\n",
      "Epoch 91/250\n",
      "162/162 [==============================] - 12s 72ms/step - loss: 0.5543 - accuracy: 0.7765 - val_loss: 0.5639 - val_accuracy: 0.8173\n",
      "Epoch 92/250\n",
      "162/162 [==============================] - 12s 74ms/step - loss: 0.5561 - accuracy: 0.7777 - val_loss: 0.5743 - val_accuracy: 0.7895\n",
      "Epoch 93/250\n",
      "162/162 [==============================] - 11s 71ms/step - loss: 0.5615 - accuracy: 0.7812 - val_loss: 0.5068 - val_accuracy: 0.7330\n",
      "Epoch 94/250\n",
      "162/162 [==============================] - 14s 86ms/step - loss: 0.5145 - accuracy: 0.7779 - val_loss: 0.5692 - val_accuracy: 0.7562\n",
      "Epoch 95/250\n",
      "162/162 [==============================] - 12s 75ms/step - loss: 0.5373 - accuracy: 0.7810 - val_loss: 0.5477 - val_accuracy: 0.6997\n",
      "Epoch 96/250\n",
      "162/162 [==============================] - 12s 71ms/step - loss: 0.4996 - accuracy: 0.7725 - val_loss: 0.5115 - val_accuracy: 0.7763\n",
      "Epoch 97/250\n",
      "162/162 [==============================] - 12s 74ms/step - loss: 0.5113 - accuracy: 0.7798 - val_loss: 0.5253 - val_accuracy: 0.7964\n",
      "Epoch 98/250\n",
      "162/162 [==============================] - 12s 75ms/step - loss: 0.5417 - accuracy: 0.7676 - val_loss: 0.5469 - val_accuracy: 0.7392\n",
      "Epoch 99/250\n",
      "162/162 [==============================] - 12s 77ms/step - loss: 0.5136 - accuracy: 0.7734 - val_loss: 0.5170 - val_accuracy: 0.7872\n",
      "Epoch 100/250\n",
      "162/162 [==============================] - 12s 75ms/step - loss: 0.4965 - accuracy: 0.7852 - val_loss: 0.4958 - val_accuracy: 0.8212\n",
      "Epoch 101/250\n",
      "162/162 [==============================] - 12s 71ms/step - loss: 0.4902 - accuracy: 0.7895 - val_loss: 0.5454 - val_accuracy: 0.7570\n",
      "Epoch 102/250\n",
      "162/162 [==============================] - 12s 77ms/step - loss: 0.4903 - accuracy: 0.7922 - val_loss: 0.5348 - val_accuracy: 0.8111\n",
      "Epoch 103/250\n",
      "162/162 [==============================] - 11s 71ms/step - loss: 0.5071 - accuracy: 0.7974 - val_loss: 0.6632 - val_accuracy: 0.7345\n",
      "Epoch 104/250\n",
      "162/162 [==============================] - 12s 74ms/step - loss: 0.5546 - accuracy: 0.7504 - val_loss: 0.5153 - val_accuracy: 0.8073\n",
      "Epoch 105/250\n",
      "162/162 [==============================] - 12s 71ms/step - loss: 0.4970 - accuracy: 0.7969 - val_loss: 0.5376 - val_accuracy: 0.7918\n",
      "Epoch 106/250\n",
      "162/162 [==============================] - 12s 75ms/step - loss: 0.5518 - accuracy: 0.7593 - val_loss: 0.5395 - val_accuracy: 0.7949\n",
      "Epoch 107/250\n",
      "162/162 [==============================] - 12s 74ms/step - loss: 0.4972 - accuracy: 0.7916 - val_loss: 0.5199 - val_accuracy: 0.7748\n",
      "Epoch 108/250\n",
      "162/162 [==============================] - 12s 77ms/step - loss: 0.4915 - accuracy: 0.7918 - val_loss: 0.5101 - val_accuracy: 0.7593\n",
      "Epoch 109/250\n",
      "162/162 [==============================] - 12s 73ms/step - loss: 0.4794 - accuracy: 0.7938 - val_loss: 0.5101 - val_accuracy: 0.8111\n",
      "Epoch 110/250\n",
      "162/162 [==============================] - 12s 74ms/step - loss: 0.4878 - accuracy: 0.7951 - val_loss: 0.5128 - val_accuracy: 0.8003\n",
      "Epoch 111/250\n",
      "162/162 [==============================] - 13s 78ms/step - loss: 0.4880 - accuracy: 0.8003 - val_loss: 0.5138 - val_accuracy: 0.8220\n",
      "Epoch 112/250\n",
      "162/162 [==============================] - 12s 76ms/step - loss: 0.4633 - accuracy: 0.8038 - val_loss: 0.5069 - val_accuracy: 0.7926\n",
      "Epoch 113/250\n",
      "162/162 [==============================] - 12s 73ms/step - loss: 0.4717 - accuracy: 0.8009 - val_loss: 0.5430 - val_accuracy: 0.7709\n",
      "Epoch 114/250\n",
      "162/162 [==============================] - 13s 81ms/step - loss: 0.4825 - accuracy: 0.8009 - val_loss: 0.5061 - val_accuracy: 0.7864\n",
      "Epoch 115/250\n",
      "162/162 [==============================] - 12s 73ms/step - loss: 0.4587 - accuracy: 0.8025 - val_loss: 0.5383 - val_accuracy: 0.7647\n",
      "Epoch 116/250\n",
      "162/162 [==============================] - 12s 74ms/step - loss: 0.4549 - accuracy: 0.8093 - val_loss: 0.6068 - val_accuracy: 0.8096\n",
      "Epoch 117/250\n",
      "162/162 [==============================] - 12s 76ms/step - loss: 0.5070 - accuracy: 0.7821 - val_loss: 0.4972 - val_accuracy: 0.7786\n",
      "Epoch 118/250\n",
      "162/162 [==============================] - 12s 75ms/step - loss: 0.4527 - accuracy: 0.8019 - val_loss: 0.4882 - val_accuracy: 0.8127\n",
      "Epoch 119/250\n",
      "162/162 [==============================] - 13s 81ms/step - loss: 0.4398 - accuracy: 0.8019 - val_loss: 0.4940 - val_accuracy: 0.8166\n",
      "Epoch 120/250\n",
      "162/162 [==============================] - 13s 77ms/step - loss: 0.4478 - accuracy: 0.8085 - val_loss: 0.4652 - val_accuracy: 0.8011\n",
      "Epoch 121/250\n",
      "162/162 [==============================] - 13s 78ms/step - loss: 0.4395 - accuracy: 0.8031 - val_loss: 0.4876 - val_accuracy: 0.8266\n",
      "Epoch 122/250\n",
      "162/162 [==============================] - 12s 75ms/step - loss: 0.4524 - accuracy: 0.8110 - val_loss: 0.5209 - val_accuracy: 0.8289\n",
      "Epoch 123/250\n",
      "162/162 [==============================] - 12s 72ms/step - loss: 0.4921 - accuracy: 0.7812 - val_loss: 0.5593 - val_accuracy: 0.8251\n",
      "Epoch 124/250\n",
      "162/162 [==============================] - 12s 72ms/step - loss: 0.5013 - accuracy: 0.8021 - val_loss: 0.4919 - val_accuracy: 0.8289\n",
      "Epoch 125/250\n",
      "162/162 [==============================] - 13s 78ms/step - loss: 0.5370 - accuracy: 0.7676 - val_loss: 0.5341 - val_accuracy: 0.8328\n",
      "Epoch 126/250\n",
      "162/162 [==============================] - 12s 77ms/step - loss: 0.4583 - accuracy: 0.8011 - val_loss: 0.4860 - val_accuracy: 0.7717\n",
      "Epoch 127/250\n",
      "162/162 [==============================] - 12s 74ms/step - loss: 0.4388 - accuracy: 0.8075 - val_loss: 0.4801 - val_accuracy: 0.8026\n",
      "Epoch 128/250\n",
      "162/162 [==============================] - 12s 74ms/step - loss: 0.4670 - accuracy: 0.8044 - val_loss: 0.5223 - val_accuracy: 0.7446\n",
      "Epoch 129/250\n",
      "162/162 [==============================] - 12s 75ms/step - loss: 0.4631 - accuracy: 0.8025 - val_loss: 0.4890 - val_accuracy: 0.8251\n",
      "Epoch 130/250\n",
      "162/162 [==============================] - 12s 75ms/step - loss: 0.4622 - accuracy: 0.8009 - val_loss: 0.5208 - val_accuracy: 0.7833\n",
      "Epoch 131/250\n",
      "162/162 [==============================] - 12s 74ms/step - loss: 0.4512 - accuracy: 0.8127 - val_loss: 0.4767 - val_accuracy: 0.8003\n",
      "Epoch 132/250\n",
      "162/162 [==============================] - 11s 70ms/step - loss: 0.4285 - accuracy: 0.8102 - val_loss: 0.5069 - val_accuracy: 0.7632\n",
      "Epoch 133/250\n",
      "162/162 [==============================] - 12s 74ms/step - loss: 0.4216 - accuracy: 0.8143 - val_loss: 0.4975 - val_accuracy: 0.8173\n",
      "Epoch 134/250\n",
      "162/162 [==============================] - 12s 76ms/step - loss: 0.4214 - accuracy: 0.8133 - val_loss: 0.4944 - val_accuracy: 0.8034\n",
      "Epoch 135/250\n",
      "162/162 [==============================] - 12s 73ms/step - loss: 0.4220 - accuracy: 0.8162 - val_loss: 0.4876 - val_accuracy: 0.8111\n",
      "Epoch 136/250\n",
      "162/162 [==============================] - 13s 80ms/step - loss: 0.5434 - accuracy: 0.7508 - val_loss: 0.6180 - val_accuracy: 0.7902\n",
      "Epoch 137/250\n",
      "162/162 [==============================] - 12s 73ms/step - loss: 0.4980 - accuracy: 0.7903 - val_loss: 0.5053 - val_accuracy: 0.8127\n",
      "Epoch 138/250\n",
      "162/162 [==============================] - 12s 71ms/step - loss: 0.4659 - accuracy: 0.8056 - val_loss: 0.4716 - val_accuracy: 0.7972\n",
      "Epoch 139/250\n",
      "162/162 [==============================] - 12s 74ms/step - loss: 0.4351 - accuracy: 0.8155 - val_loss: 0.4489 - val_accuracy: 0.7988\n",
      "Epoch 140/250\n",
      "162/162 [==============================] - 12s 75ms/step - loss: 0.4164 - accuracy: 0.8160 - val_loss: 0.4398 - val_accuracy: 0.8104\n",
      "Epoch 141/250\n",
      "162/162 [==============================] - 12s 76ms/step - loss: 0.4322 - accuracy: 0.8168 - val_loss: 0.4581 - val_accuracy: 0.7957\n",
      "Epoch 142/250\n",
      "162/162 [==============================] - 12s 74ms/step - loss: 0.4310 - accuracy: 0.8141 - val_loss: 0.5285 - val_accuracy: 0.8266\n",
      "Epoch 143/250\n",
      "162/162 [==============================] - 13s 82ms/step - loss: 0.4272 - accuracy: 0.8145 - val_loss: 0.4536 - val_accuracy: 0.7833\n",
      "Epoch 144/250\n",
      "162/162 [==============================] - 14s 84ms/step - loss: 0.4408 - accuracy: 0.8133 - val_loss: 0.4681 - val_accuracy: 0.8228\n",
      "Epoch 145/250\n",
      "162/162 [==============================] - 13s 83ms/step - loss: 0.4199 - accuracy: 0.8213 - val_loss: 0.4938 - val_accuracy: 0.7848\n",
      "Epoch 146/250\n",
      "162/162 [==============================] - 12s 77ms/step - loss: 0.4149 - accuracy: 0.8226 - val_loss: 0.4741 - val_accuracy: 0.7872\n",
      "Epoch 147/250\n",
      "162/162 [==============================] - 12s 74ms/step - loss: 0.4031 - accuracy: 0.8199 - val_loss: 0.5079 - val_accuracy: 0.8026\n",
      "Epoch 148/250\n",
      "162/162 [==============================] - 12s 74ms/step - loss: 0.4081 - accuracy: 0.8218 - val_loss: 0.4862 - val_accuracy: 0.7872\n",
      "Epoch 149/250\n",
      "162/162 [==============================] - 13s 78ms/step - loss: 0.4043 - accuracy: 0.8286 - val_loss: 0.4736 - val_accuracy: 0.8305\n",
      "Epoch 150/250\n",
      "162/162 [==============================] - 14s 86ms/step - loss: 0.4308 - accuracy: 0.8216 - val_loss: 0.5217 - val_accuracy: 0.7941\n",
      "Epoch 151/250\n",
      "162/162 [==============================] - 13s 79ms/step - loss: 0.3954 - accuracy: 0.8249 - val_loss: 0.5042 - val_accuracy: 0.8235\n",
      "Epoch 152/250\n",
      "162/162 [==============================] - 12s 74ms/step - loss: 0.4198 - accuracy: 0.8327 - val_loss: 0.4923 - val_accuracy: 0.7910\n",
      "Epoch 153/250\n",
      "162/162 [==============================] - 13s 78ms/step - loss: 0.4192 - accuracy: 0.8093 - val_loss: 0.5860 - val_accuracy: 0.6370\n",
      "Epoch 154/250\n",
      "162/162 [==============================] - 12s 76ms/step - loss: 0.4420 - accuracy: 0.7914 - val_loss: 0.5229 - val_accuracy: 0.8166\n",
      "Epoch 155/250\n",
      "162/162 [==============================] - 12s 75ms/step - loss: 0.4117 - accuracy: 0.8255 - val_loss: 0.4842 - val_accuracy: 0.8135\n",
      "Epoch 156/250\n",
      "162/162 [==============================] - 12s 76ms/step - loss: 0.4063 - accuracy: 0.8340 - val_loss: 0.4701 - val_accuracy: 0.8057\n",
      "Epoch 157/250\n",
      "162/162 [==============================] - 12s 76ms/step - loss: 0.4273 - accuracy: 0.8211 - val_loss: 0.5588 - val_accuracy: 0.7957\n",
      "Epoch 158/250\n",
      "162/162 [==============================] - 12s 76ms/step - loss: 0.3997 - accuracy: 0.8300 - val_loss: 0.4745 - val_accuracy: 0.8119\n",
      "Epoch 159/250\n",
      "162/162 [==============================] - 12s 75ms/step - loss: 0.3822 - accuracy: 0.8373 - val_loss: 0.5324 - val_accuracy: 0.8328\n",
      "Epoch 160/250\n",
      "162/162 [==============================] - 12s 75ms/step - loss: 0.4574 - accuracy: 0.8073 - val_loss: 0.6073 - val_accuracy: 0.7167\n",
      "Epoch 161/250\n",
      "162/162 [==============================] - 12s 76ms/step - loss: 0.4693 - accuracy: 0.7789 - val_loss: 0.4804 - val_accuracy: 0.8181\n",
      "Epoch 162/250\n",
      "162/162 [==============================] - 11s 70ms/step - loss: 0.4032 - accuracy: 0.8337 - val_loss: 0.4827 - val_accuracy: 0.8166\n",
      "Epoch 163/250\n",
      "162/162 [==============================] - 11s 71ms/step - loss: 0.3896 - accuracy: 0.8327 - val_loss: 0.4939 - val_accuracy: 0.8057\n",
      "Epoch 164/250\n",
      "162/162 [==============================] - 12s 74ms/step - loss: 0.3810 - accuracy: 0.8412 - val_loss: 0.5111 - val_accuracy: 0.7887\n",
      "Epoch 165/250\n",
      "162/162 [==============================] - 12s 74ms/step - loss: 0.3899 - accuracy: 0.8364 - val_loss: 0.4800 - val_accuracy: 0.8073\n",
      "Epoch 166/250\n",
      "162/162 [==============================] - 12s 76ms/step - loss: 0.3620 - accuracy: 0.8493 - val_loss: 0.5088 - val_accuracy: 0.8111\n",
      "Epoch 167/250\n",
      "162/162 [==============================] - 12s 73ms/step - loss: 0.4329 - accuracy: 0.8329 - val_loss: 0.5100 - val_accuracy: 0.7957\n",
      "Epoch 168/250\n",
      "162/162 [==============================] - 12s 76ms/step - loss: 0.3690 - accuracy: 0.8410 - val_loss: 0.5122 - val_accuracy: 0.7980\n",
      "Epoch 169/250\n",
      "162/162 [==============================] - 12s 74ms/step - loss: 0.3497 - accuracy: 0.8522 - val_loss: 0.4815 - val_accuracy: 0.8111\n",
      "Epoch 170/250\n",
      "162/162 [==============================] - 12s 76ms/step - loss: 0.3670 - accuracy: 0.8420 - val_loss: 0.5586 - val_accuracy: 0.8204\n",
      "Epoch 171/250\n",
      "162/162 [==============================] - 12s 72ms/step - loss: 0.3569 - accuracy: 0.8552 - val_loss: 0.5634 - val_accuracy: 0.8127\n",
      "Epoch 172/250\n",
      "162/162 [==============================] - 12s 76ms/step - loss: 0.3349 - accuracy: 0.8563 - val_loss: 0.7039 - val_accuracy: 0.8297\n",
      "Epoch 173/250\n",
      "162/162 [==============================] - 12s 76ms/step - loss: 0.3567 - accuracy: 0.8582 - val_loss: 0.5991 - val_accuracy: 0.7941\n",
      "Epoch 174/250\n",
      "162/162 [==============================] - 12s 76ms/step - loss: 0.3402 - accuracy: 0.8598 - val_loss: 0.5916 - val_accuracy: 0.8204\n",
      "Epoch 175/250\n",
      "162/162 [==============================] - 12s 76ms/step - loss: 0.3392 - accuracy: 0.8627 - val_loss: 0.6251 - val_accuracy: 0.8336\n",
      "Epoch 176/250\n",
      "162/162 [==============================] - 13s 78ms/step - loss: 0.4608 - accuracy: 0.8168 - val_loss: 0.5866 - val_accuracy: 0.7159\n",
      "Epoch 177/250\n",
      "162/162 [==============================] - 12s 75ms/step - loss: 0.4675 - accuracy: 0.7982 - val_loss: 0.5331 - val_accuracy: 0.8057\n",
      "Epoch 178/250\n",
      "162/162 [==============================] - 13s 80ms/step - loss: 0.4465 - accuracy: 0.8145 - val_loss: 0.5138 - val_accuracy: 0.7980\n",
      "Epoch 179/250\n",
      "162/162 [==============================] - 12s 74ms/step - loss: 0.4069 - accuracy: 0.8387 - val_loss: 0.5321 - val_accuracy: 0.8142\n",
      "Epoch 180/250\n",
      "162/162 [==============================] - 13s 81ms/step - loss: 0.3799 - accuracy: 0.8522 - val_loss: 0.5276 - val_accuracy: 0.8173\n",
      "Epoch 181/250\n",
      "162/162 [==============================] - 13s 78ms/step - loss: 0.3721 - accuracy: 0.8472 - val_loss: 0.5557 - val_accuracy: 0.8313\n",
      "Epoch 182/250\n",
      "162/162 [==============================] - 12s 74ms/step - loss: 0.3732 - accuracy: 0.8604 - val_loss: 0.5871 - val_accuracy: 0.8142\n",
      "Epoch 183/250\n",
      "162/162 [==============================] - 12s 77ms/step - loss: 0.3574 - accuracy: 0.8565 - val_loss: 0.5818 - val_accuracy: 0.8189\n",
      "Epoch 184/250\n",
      "162/162 [==============================] - 13s 82ms/step - loss: 0.3414 - accuracy: 0.8656 - val_loss: 0.6145 - val_accuracy: 0.8104\n",
      "Epoch 185/250\n",
      "162/162 [==============================] - 13s 81ms/step - loss: 0.3486 - accuracy: 0.8722 - val_loss: 0.6430 - val_accuracy: 0.8088\n",
      "Epoch 186/250\n",
      "162/162 [==============================] - 13s 83ms/step - loss: 0.3323 - accuracy: 0.8679 - val_loss: 0.6447 - val_accuracy: 0.8096\n",
      "Epoch 187/250\n",
      "162/162 [==============================] - 14s 84ms/step - loss: 0.3120 - accuracy: 0.8801 - val_loss: 0.6762 - val_accuracy: 0.8096\n",
      "Epoch 188/250\n",
      "162/162 [==============================] - 12s 77ms/step - loss: 0.3180 - accuracy: 0.8840 - val_loss: 0.7407 - val_accuracy: 0.8189\n",
      "Epoch 189/250\n",
      "162/162 [==============================] - 12s 76ms/step - loss: 0.2967 - accuracy: 0.8828 - val_loss: 0.7673 - val_accuracy: 0.8104\n",
      "Epoch 190/250\n",
      "162/162 [==============================] - 13s 79ms/step - loss: 0.2864 - accuracy: 0.8877 - val_loss: 0.7969 - val_accuracy: 0.8127\n",
      "Epoch 191/250\n",
      "162/162 [==============================] - 12s 72ms/step - loss: 0.3136 - accuracy: 0.8929 - val_loss: 0.5876 - val_accuracy: 0.8073\n",
      "Epoch 192/250\n",
      "162/162 [==============================] - 15s 91ms/step - loss: 0.2916 - accuracy: 0.8881 - val_loss: 0.8226 - val_accuracy: 0.8189\n",
      "Epoch 193/250\n",
      "162/162 [==============================] - 12s 76ms/step - loss: 0.2766 - accuracy: 0.8966 - val_loss: 0.9279 - val_accuracy: 0.8104\n",
      "Epoch 194/250\n",
      "162/162 [==============================] - 12s 72ms/step - loss: 0.2692 - accuracy: 0.9009 - val_loss: 0.8621 - val_accuracy: 0.8096\n",
      "Epoch 195/250\n",
      "162/162 [==============================] - 13s 82ms/step - loss: 0.2431 - accuracy: 0.9136 - val_loss: 1.0636 - val_accuracy: 0.8282\n",
      "Epoch 196/250\n",
      "162/162 [==============================] - 13s 80ms/step - loss: 0.2526 - accuracy: 0.9132 - val_loss: 0.9061 - val_accuracy: 0.7995\n",
      "Epoch 197/250\n",
      "162/162 [==============================] - 13s 81ms/step - loss: 0.2458 - accuracy: 0.9069 - val_loss: 0.9337 - val_accuracy: 0.8266\n",
      "Epoch 198/250\n",
      "162/162 [==============================] - 13s 82ms/step - loss: 0.2354 - accuracy: 0.9165 - val_loss: 0.8557 - val_accuracy: 0.8096\n",
      "Epoch 199/250\n",
      "162/162 [==============================] - 13s 79ms/step - loss: 0.2177 - accuracy: 0.9216 - val_loss: 1.0836 - val_accuracy: 0.8166\n",
      "Epoch 200/250\n",
      "162/162 [==============================] - 12s 74ms/step - loss: 0.2383 - accuracy: 0.9173 - val_loss: 0.7688 - val_accuracy: 0.8150\n",
      "Epoch 201/250\n",
      "162/162 [==============================] - 12s 75ms/step - loss: 0.2906 - accuracy: 0.9009 - val_loss: 0.9778 - val_accuracy: 0.8166\n",
      "Epoch 202/250\n",
      "162/162 [==============================] - 12s 74ms/step - loss: 0.2920 - accuracy: 0.8958 - val_loss: 0.8975 - val_accuracy: 0.8073\n",
      "Epoch 203/250\n",
      "162/162 [==============================] - 13s 80ms/step - loss: 0.2282 - accuracy: 0.9191 - val_loss: 1.0628 - val_accuracy: 0.8119\n",
      "Epoch 204/250\n",
      "162/162 [==============================] - 12s 77ms/step - loss: 0.2649 - accuracy: 0.9140 - val_loss: 0.7942 - val_accuracy: 0.8166\n",
      "Epoch 205/250\n",
      "162/162 [==============================] - 12s 73ms/step - loss: 0.2291 - accuracy: 0.9229 - val_loss: 1.2742 - val_accuracy: 0.8011\n",
      "Epoch 206/250\n",
      "162/162 [==============================] - 12s 77ms/step - loss: 0.4147 - accuracy: 0.8579 - val_loss: 1.1931 - val_accuracy: 0.7113\n",
      "Epoch 207/250\n",
      "162/162 [==============================] - 12s 76ms/step - loss: 0.4641 - accuracy: 0.8195 - val_loss: 0.5357 - val_accuracy: 0.8019\n",
      "Epoch 208/250\n",
      "162/162 [==============================] - 13s 78ms/step - loss: 0.4036 - accuracy: 0.8389 - val_loss: 0.5325 - val_accuracy: 0.8142\n",
      "Epoch 209/250\n",
      "162/162 [==============================] - 14s 87ms/step - loss: 0.3785 - accuracy: 0.8577 - val_loss: 0.5827 - val_accuracy: 0.8220\n",
      "Epoch 210/250\n",
      "162/162 [==============================] - 13s 79ms/step - loss: 0.4099 - accuracy: 0.8449 - val_loss: 0.6460 - val_accuracy: 0.7763\n",
      "Epoch 211/250\n",
      "162/162 [==============================] - 14s 87ms/step - loss: 0.3761 - accuracy: 0.8524 - val_loss: 0.5735 - val_accuracy: 0.8181\n",
      "Epoch 212/250\n",
      "162/162 [==============================] - 12s 74ms/step - loss: 0.3314 - accuracy: 0.8751 - val_loss: 0.6481 - val_accuracy: 0.8243\n",
      "Epoch 213/250\n",
      "162/162 [==============================] - 12s 74ms/step - loss: 0.3107 - accuracy: 0.8821 - val_loss: 0.7650 - val_accuracy: 0.8150\n",
      "Epoch 214/250\n",
      "162/162 [==============================] - 12s 75ms/step - loss: 0.2950 - accuracy: 0.9007 - val_loss: 0.6971 - val_accuracy: 0.8042\n",
      "Epoch 215/250\n",
      "162/162 [==============================] - 13s 78ms/step - loss: 0.2679 - accuracy: 0.9047 - val_loss: 0.9526 - val_accuracy: 0.7980\n",
      "Epoch 216/250\n",
      "162/162 [==============================] - 14s 84ms/step - loss: 0.2971 - accuracy: 0.9001 - val_loss: 0.8551 - val_accuracy: 0.8019\n",
      "Epoch 217/250\n",
      "162/162 [==============================] - 12s 76ms/step - loss: 0.2728 - accuracy: 0.9140 - val_loss: 0.9319 - val_accuracy: 0.8142\n",
      "Epoch 218/250\n",
      "162/162 [==============================] - 12s 75ms/step - loss: 0.2413 - accuracy: 0.9225 - val_loss: 1.0733 - val_accuracy: 0.7918\n",
      "Epoch 219/250\n",
      "162/162 [==============================] - 13s 79ms/step - loss: 0.2667 - accuracy: 0.9179 - val_loss: 1.0850 - val_accuracy: 0.8150\n",
      "Epoch 220/250\n",
      "162/162 [==============================] - 14s 85ms/step - loss: 0.2199 - accuracy: 0.9313 - val_loss: 1.1239 - val_accuracy: 0.8019\n",
      "Epoch 221/250\n",
      "162/162 [==============================] - 13s 81ms/step - loss: 0.2384 - accuracy: 0.9212 - val_loss: 0.9243 - val_accuracy: 0.8019\n",
      "Epoch 222/250\n",
      "162/162 [==============================] - 12s 77ms/step - loss: 0.3584 - accuracy: 0.8792 - val_loss: 0.7681 - val_accuracy: 0.8142\n",
      "Epoch 223/250\n",
      "162/162 [==============================] - 13s 80ms/step - loss: 0.3017 - accuracy: 0.9022 - val_loss: 0.9164 - val_accuracy: 0.7872\n",
      "Epoch 224/250\n",
      "162/162 [==============================] - 13s 78ms/step - loss: 0.2471 - accuracy: 0.9189 - val_loss: 1.0970 - val_accuracy: 0.7949\n",
      "Epoch 225/250\n",
      "162/162 [==============================] - 13s 77ms/step - loss: 0.2396 - accuracy: 0.9256 - val_loss: 1.0313 - val_accuracy: 0.8259\n",
      "Epoch 226/250\n",
      "162/162 [==============================] - 12s 77ms/step - loss: 0.2057 - accuracy: 0.9359 - val_loss: 1.2124 - val_accuracy: 0.8057\n",
      "Epoch 227/250\n",
      "162/162 [==============================] - 13s 80ms/step - loss: 0.1955 - accuracy: 0.9477 - val_loss: 1.3548 - val_accuracy: 0.7864\n",
      "Epoch 228/250\n",
      "162/162 [==============================] - 12s 76ms/step - loss: 0.3620 - accuracy: 0.8898 - val_loss: 0.9291 - val_accuracy: 0.8142\n",
      "Epoch 229/250\n",
      "162/162 [==============================] - 13s 80ms/step - loss: 0.2544 - accuracy: 0.9262 - val_loss: 1.0833 - val_accuracy: 0.8080\n",
      "Epoch 230/250\n",
      "162/162 [==============================] - 13s 77ms/step - loss: 0.2163 - accuracy: 0.9398 - val_loss: 1.2065 - val_accuracy: 0.8104\n",
      "Epoch 231/250\n",
      "162/162 [==============================] - 13s 78ms/step - loss: 0.1946 - accuracy: 0.9531 - val_loss: 1.8552 - val_accuracy: 0.8034\n",
      "Epoch 232/250\n",
      "162/162 [==============================] - 13s 80ms/step - loss: 0.5978 - accuracy: 0.8156 - val_loss: 0.7188 - val_accuracy: 0.7670\n",
      "Epoch 233/250\n",
      "162/162 [==============================] - 14s 84ms/step - loss: 0.4015 - accuracy: 0.8557 - val_loss: 0.7199 - val_accuracy: 0.8003\n",
      "Epoch 234/250\n",
      "162/162 [==============================] - 14s 86ms/step - loss: 0.3600 - accuracy: 0.8674 - val_loss: 0.7352 - val_accuracy: 0.8135\n",
      "Epoch 235/250\n",
      "162/162 [==============================] - 13s 80ms/step - loss: 0.2960 - accuracy: 0.8966 - val_loss: 0.7960 - val_accuracy: 0.8336\n",
      "Epoch 236/250\n",
      "162/162 [==============================] - 13s 78ms/step - loss: 0.3235 - accuracy: 0.8846 - val_loss: 0.8796 - val_accuracy: 0.8003\n",
      "Epoch 237/250\n",
      "162/162 [==============================] - 13s 79ms/step - loss: 0.2804 - accuracy: 0.9026 - val_loss: 0.9323 - val_accuracy: 0.8158\n",
      "Epoch 238/250\n",
      "162/162 [==============================] - 13s 78ms/step - loss: 0.2860 - accuracy: 0.8978 - val_loss: 0.7938 - val_accuracy: 0.7399\n",
      "Epoch 239/250\n",
      "162/162 [==============================] - 13s 79ms/step - loss: 0.2818 - accuracy: 0.9020 - val_loss: 1.0582 - val_accuracy: 0.8104\n",
      "Epoch 240/250\n",
      "162/162 [==============================] - 13s 77ms/step - loss: 0.2364 - accuracy: 0.9280 - val_loss: 1.2293 - val_accuracy: 0.7879\n",
      "Epoch 241/250\n",
      "162/162 [==============================] - 13s 79ms/step - loss: 0.2365 - accuracy: 0.9272 - val_loss: 1.0786 - val_accuracy: 0.7988\n",
      "Epoch 242/250\n",
      "162/162 [==============================] - 12s 77ms/step - loss: 0.2003 - accuracy: 0.9384 - val_loss: 1.2344 - val_accuracy: 0.7926\n",
      "Epoch 243/250\n",
      "162/162 [==============================] - 13s 82ms/step - loss: 0.1738 - accuracy: 0.9493 - val_loss: 1.4084 - val_accuracy: 0.8065\n",
      "Epoch 244/250\n",
      "162/162 [==============================] - 13s 80ms/step - loss: 0.2085 - accuracy: 0.9371 - val_loss: 1.4404 - val_accuracy: 0.7856\n",
      "Epoch 245/250\n",
      "162/162 [==============================] - 13s 79ms/step - loss: 0.1820 - accuracy: 0.9485 - val_loss: 1.4189 - val_accuracy: 0.8104\n",
      "Epoch 246/250\n",
      "162/162 [==============================] - 13s 80ms/step - loss: 0.1442 - accuracy: 0.9648 - val_loss: 1.6013 - val_accuracy: 0.7941\n",
      "Epoch 247/250\n",
      "162/162 [==============================] - 12s 77ms/step - loss: 0.1736 - accuracy: 0.9508 - val_loss: 1.2922 - val_accuracy: 0.8026\n",
      "Epoch 248/250\n",
      "162/162 [==============================] - 13s 79ms/step - loss: 0.1502 - accuracy: 0.9649 - val_loss: 1.5559 - val_accuracy: 0.7941\n",
      "Epoch 249/250\n",
      "162/162 [==============================] - 13s 81ms/step - loss: 0.1515 - accuracy: 0.9673 - val_loss: 1.6781 - val_accuracy: 0.8080\n",
      "Epoch 250/250\n",
      "162/162 [==============================] - 13s 78ms/step - loss: 0.1899 - accuracy: 0.9611 - val_loss: 1.6180 - val_accuracy: 0.7779\n",
      "Best epoch: 175\n"
     ]
    }
   ],
   "source": [
    "best_hps=tuner.get_best_hyperparameters()[0]\n",
    "\n",
    "# Build the model with the optimal hyperparameters and train it on the data for 50 epochs\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(x_train, y_train, epochs=250, validation_data=(x_val, y_val))\n",
    "\n",
    "val_acc_per_epoch = history.history['val_accuracy']\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f02c7c3-c36e-46d4-b19f-9795466f5c9d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 30] Read-only file system: '/stevecostalat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m hypermodel \u001b[38;5;241m=\u001b[39m tuner\u001b[38;5;241m.\u001b[39mhypermodel\u001b[38;5;241m.\u001b[39mbuild(best_hps)\n\u001b[1;32m     19\u001b[0m keras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mplot_model(hypermodel,to_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel.png\u001b[39m\u001b[38;5;124m\"\u001b[39m, show_shapes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 21\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mlog_artifact(PATH_DIR \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Tuning.txt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     22\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mlog_artifact(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     24\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mlog_param(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeuil\u001b[39m\u001b[38;5;124m\"\u001b[39m, best_hps\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthresh\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/envs/Projet/lib/python3.11/site-packages/mlflow/tracking/fluent.py:986\u001b[0m, in \u001b[0;36mlog_artifact\u001b[0;34m(local_path, artifact_path)\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    964\u001b[0m \u001b[38;5;124;03mLog a local file or directory as an artifact of the currently active run. If no run is\u001b[39;00m\n\u001b[1;32m    965\u001b[0m \u001b[38;5;124;03mactive, this method will create a new active run.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;124;03m        mlflow.log_artifact(\"features.txt\")\u001b[39;00m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    985\u001b[0m run_id \u001b[38;5;241m=\u001b[39m _get_or_start_run()\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mrun_id\n\u001b[0;32m--> 986\u001b[0m MlflowClient()\u001b[38;5;241m.\u001b[39mlog_artifact(run_id, local_path, artifact_path)\n",
      "File \u001b[0;32m~/miniconda3/envs/Projet/lib/python3.11/site-packages/mlflow/tracking/client.py:1142\u001b[0m, in \u001b[0;36mMlflowClient.log_artifact\u001b[0;34m(self, run_id, local_path, artifact_path)\u001b[0m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlog_artifact\u001b[39m(\u001b[38;5;28mself\u001b[39m, run_id, local_path, artifact_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1109\u001b[0m \u001b[38;5;124;03m    Write a local file or directory to the remote ``artifact_uri``.\u001b[39;00m\n\u001b[1;32m   1110\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;124;03m        is_dir: False\u001b[39;00m\n\u001b[1;32m   1141\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1142\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tracking_client\u001b[38;5;241m.\u001b[39mlog_artifact(run_id, local_path, artifact_path)\n",
      "File \u001b[0;32m~/miniconda3/envs/Projet/lib/python3.11/site-packages/mlflow/tracking/_tracking_service/client.py:529\u001b[0m, in \u001b[0;36mTrackingServiceClient.log_artifact\u001b[0;34m(self, run_id, local_path, artifact_path)\u001b[0m\n\u001b[1;32m    527\u001b[0m     artifact_repo\u001b[38;5;241m.\u001b[39mlog_artifacts(local_path, path_name)\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 529\u001b[0m     artifact_repo\u001b[38;5;241m.\u001b[39mlog_artifact(local_path, artifact_path)\n",
      "File \u001b[0;32m~/miniconda3/envs/Projet/lib/python3.11/site-packages/mlflow/store/artifact/local_artifact_repo.py:36\u001b[0m, in \u001b[0;36mLocalArtifactRepository.log_artifact\u001b[0;34m(self, local_file, artifact_path)\u001b[0m\n\u001b[1;32m     32\u001b[0m artifact_dir \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     33\u001b[0m     os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39martifact_dir, artifact_path) \u001b[38;5;28;01mif\u001b[39;00m artifact_path \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39martifact_dir\n\u001b[1;32m     34\u001b[0m )\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(artifact_dir):\n\u001b[0;32m---> 36\u001b[0m     mkdir(artifact_dir)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     38\u001b[0m     shutil\u001b[38;5;241m.\u001b[39mcopy2(local_file, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(artifact_dir, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(local_file)))\n",
      "File \u001b[0;32m~/miniconda3/envs/Projet/lib/python3.11/site-packages/mlflow/utils/file_utils.py:204\u001b[0m, in \u001b[0;36mmkdir\u001b[0;34m(root, name)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39merrno \u001b[38;5;241m!=\u001b[39m errno\u001b[38;5;241m.\u001b[39mEEXIST \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(target):\n\u001b[0;32m--> 204\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m target\n",
      "File \u001b[0;32m~/miniconda3/envs/Projet/lib/python3.11/site-packages/mlflow/utils/file_utils.py:201\u001b[0m, in \u001b[0;36mmkdir\u001b[0;34m(root, name)\u001b[0m\n\u001b[1;32m    199\u001b[0m target \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(root, name) \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m root\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 201\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(target)\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39merrno \u001b[38;5;241m!=\u001b[39m errno\u001b[38;5;241m.\u001b[39mEEXIST \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(target):\n",
      "File \u001b[0;32m<frozen os>:215\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n",
      "File \u001b[0;32m<frozen os>:215\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n",
      "    \u001b[0;31m[... skipping similar frames: makedirs at line 215 (4 times)]\u001b[0m\n",
      "File \u001b[0;32m<frozen os>:215\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n",
      "File \u001b[0;32m<frozen os>:225\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 30] Read-only file system: '/stevecostalat'"
     ]
    }
   ],
   "source": [
    "# Importer MLflow\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "\n",
    "\n",
    "try:\n",
    "    experiment_id = mlflow.create_experiment('TUNING input Profil  ouput: Malade/Normal')\n",
    "except:\n",
    "    experiment_name = 'TUNING input Profil  ouput: Malade/Normal'\n",
    "    current_experiment=dict(mlflow.get_experiment_by_name(experiment_name))\n",
    "    experiment_id=current_experiment['experiment_id']\n",
    "\n",
    "\n",
    "with mlflow.start_run(experiment_id =experiment_id) as run:\n",
    "\n",
    "    \n",
    "\n",
    "    hypermodel = tuner.hypermodel.build(best_hps)\n",
    "    keras.utils.plot_model(hypermodel,to_file=\"Model.png\", show_shapes=True)\n",
    "    \n",
    "    mlflow.log_artifact(PATH_DIR + '/Tuning.txt')\n",
    "    mlflow.log_artifact(\"Model.png\")\n",
    "\n",
    "    mlflow.log_param(\"Seuil\", best_hps.get('thresh'))\n",
    "    mlflow.log_param(\"loss\", 'BinaryCrossentropy')\n",
    "    mlflow.log_param(\"learning rate\", best_hps.get('lr'))\n",
    "    mlflow.log_param(\"epoch\", best_epoch)\n",
    "    mlflow.log_param(\"CNN\", best_hps.get('num_conv_layer')+1)\n",
    "    mlflow.log_param(\"DNN\", best_hps.get('num_hidden_layer'))\n",
    "    \n",
    "    history = hypermodel.fit(x_train, y_train, epochs=best_epoch, validation_data=(x_val, y_val))\n",
    "    plot_history_metrics(history)\n",
    "\n",
    "    mlflow.log_artifact(\"Training and Validation.png\")\n",
    "\n",
    "    eval_result = hypermodel.evaluate(x_test, y_test)\n",
    "    y_pred = hypermodel.predict(x_test)\n",
    "    y_pred_class = np.apply_along_axis(lambda x: 1 if x>best_hps.get('thresh') else 0, 1, y_pred)\n",
    "\n",
    "    confusion_m = metrics.confusion_matrix(y_test, y_pred_class)\n",
    "                \n",
    "    VN = confusion_m[0,0]\n",
    "    VP = confusion_m[1,1]\n",
    "    FN = confusion_m[1,0]\n",
    "    FP = confusion_m[0,1]\n",
    "\n",
    "    plot_history_metrics(history)\n",
    "\n",
    "    \n",
    "    print('Justesse du jeu de test =', np.round((VP+VN)/(VP+VN+FP+FN)*100,2),'%')\n",
    "    print('Sensibilité =', np.round(VP*100/(VP+FN),2),'%')\n",
    "    print('Spécificité =', np.round(VN*100/(VN+FP),2),'%')\n",
    "\n",
    "    print('---------Matrice de confusition-----------------')\n",
    "    print('               pred:Malade     pred:Normal')\n",
    "    print('vrai Malade:      ',VP,'            ',FN)\n",
    "    print('vrai Normal       ',FP,'            ',VN)\n",
    "        \n",
    "    signature = mlflow.models.infer_signature(x_train, hypermodel.predict(x_train))\n",
    "    mlflow.keras.log_model(hypermodel, artifact_path=\"keras-model\", signature=signature)\n",
    "\n",
    "#    mlflow.log_artifact(\"Training and Validation.png\")\n",
    "    mlflow.log_metric(\"Justesse\",(VP+VN)/(VP+VN+FP+FN))\n",
    "    mlflow.log_metric(\"VN\", VN)\n",
    "    mlflow.log_metric(\"VP\", VP)\n",
    "    mlflow.log_metric(\"FN\", FN)\n",
    "    mlflow.log_metric(\"FP\", FP)\n",
    "    mlflow.log_metric(\"Sensibilite\", VP/(VP+FN))\n",
    "    mlflow.log_metric(\"Specificite\", VN/(VN+FP))\n",
    "    mlflow.log_param(\"seuil\", seuil)\n",
    "\n",
    "    mlflow.end_run()\n",
    "\n",
    "    model_uri = f\"runs:/{run.info.run_id}/keras-model\"\n",
    "    mv = mlflow.register_model(model_uri, \"Tuning 1D Le Net-like binar\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674e9547-bb17-4ade-be5c-c2650968fc28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
