{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47e8461d-786c-4d6f-818a-1ca91a15a73e",
   "metadata": {},
   "source": [
    "# Input: PROFIL: Reduction de dimmension    \n",
    "# Modele: TUNING Hyperparmètre d'un modele type LeNet 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d79e45d1-66c5-4176-9411-7b9e2685c41d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.models import Model\n",
    "\n",
    "from contextlib import redirect_stdout\n",
    "import keras_tuner as kt\n",
    "\n",
    "from sklearn import preprocessing, model_selection\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "from pickle import dump, load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9926d6-fac2-43bf-a641-ebaeab72b7b3",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2c028e4-0005-4f87-8dc6-41ec07938c10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Acquisition\n",
    "df_train = pd.read_json('Train_Intensite_H.json')\n",
    "df_train['Intensite'] = df_train['Intensite'].apply(lambda x: np.array(x)/(np.array(x).max())).tolist()\n",
    "df_test = pd.read_json('Test_Intensite_H.json')\n",
    "df_test['Intensite'] = df_test['Intensite'].apply(lambda x: np.array(x)/(np.array(x).max())).tolist()\n",
    "\n",
    "#Preprocessing\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "x_train_list = [ scaler.fit_transform(np.asarray(i).reshape(-1, 1)) for i in df_train['Intensite']]\n",
    "y_train_list = [i for i in df_train['Diagnostic']]\n",
    "x_test_list = [ scaler.fit_transform(np.asarray(i).reshape(-1, 1)) for i in df_test['Intensite']]\n",
    "y_test_list = [i for i in df_test['Diagnostic']]\n",
    "\n",
    "#Création des jeu d'entrainement, de validation et de Test\n",
    "x_train, x_val, y_train, y_val = model_selection.train_test_split(x_train_list, y_train_list, test_size=0.2, random_state=42, shuffle=True)\n",
    "x_train = np.asarray(x_train).astype(np.float32).reshape(-1, 256, 1)\n",
    "y_train = np.asarray(y_train).astype(np.float32).reshape(-1, 1)\n",
    "x_val = np.asarray(x_val).astype(np.float32).reshape(-1, 256, 1)\n",
    "y_val = np.asarray(y_val).astype(np.float32).reshape(-1, 1)\n",
    "x_test = np.asarray(x_test_list).astype(np.float32).reshape(-1, 256, 1)\n",
    "y_test = np.asarray(y_test_list).astype(np.float32).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f27ecdcd-3a20-42af-aa6b-3352d6348531",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history_metrics(history):\n",
    " acc = history.history['accuracy']\n",
    " val_acc = history.history['val_accuracy']\n",
    "\n",
    " loss = history.history['loss']\n",
    " val_loss = history.history['val_loss']\n",
    "\n",
    "    \n",
    " fig = plt.figure(figsize=(12,6))\n",
    " ax1 = fig.add_subplot(121)\n",
    "\n",
    " ax1.plot(acc, label='Training Accuracy')\n",
    " ax1.plot(val_acc, label='Validation Accuracy')\n",
    " ax1.legend(loc='lower right')\n",
    " ax1.set_title('Training and Validation Accuracy')\n",
    "\n",
    " ax2 = fig.add_subplot(122)\n",
    " ax2.plot(loss, label='Training Loss')\n",
    " ax2.plot(val_loss, label='Validation Loss')\n",
    " ax2.legend(loc='upper right')\n",
    " ax2.set_title('Training and Validation Loss')\n",
    " plt.show()\n",
    "    \n",
    " fig.savefig(\"Training and Validation.png\")\n",
    " plt.close(fig)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81822dd8-e5a4-4ce9-a8c3-b909484d0f58",
   "metadata": {
    "tags": []
   },
   "source": [
    "# SET UP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2b7cb4-a184-4f59-9315-ad7e149d1b2c",
   "metadata": {},
   "source": [
    "### Define simple function to plot all the metrics present in a keras.callbacks.History"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952e8d49-b667-4cc8-8731-09cf5d9f8c27",
   "metadata": {},
   "source": [
    "### build_model function to generate 1D LeNet Like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2083e4eb-8c72-4e07-bef5-aecbe051ae03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "\n",
    "    # Model Variables\n",
    "    loss = keras.losses.BinaryCrossentropy()\n",
    "    thresh = 0.3\n",
    "    l_rate = 0.00011181404254174737\n",
    "    adam = tf.keras.optimizers.Adam(learning_rate= l_rate)\n",
    "    metric = [keras.metrics.BinaryAccuracy(name ='accuracy', threshold= thresh)]\n",
    "\n",
    "\n",
    "    # Model architecture    \n",
    "    input_layer = keras.Input(shape=(256, 1))\n",
    "\n",
    "    x = layers.Conv1D(filters=256,kernel_size=3, strides=2, activation=\"relu\")(input_layer)\n",
    "    x = layers.Conv1D(filters=512,kernel_size=5, strides=2, activation=\"relu\")(x)\n",
    "    x = layers.Conv1D(filters=256,kernel_size=5, strides=2, activation=\"relu\")(x)\n",
    "    x = layers.Conv1D(filters=1024,kernel_size=5, strides=2, activation=\"tanh\")(x)\n",
    "    x = layers.Conv1D(filters=128,kernel_size=5, strides=2, activation=\"relu\")(x)\n",
    "    x = layers.Conv1D(filters=32,kernel_size=5, strides=2, activation=\"relu\")(x)\n",
    "    \n",
    "    \n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Flatten()(x)\n",
    "\n",
    "    x = layers.Dense(256, activation=\"relu\", kernel_regularizer=keras.regularizers.L2())(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    x = layers.Dense(units=64, activation=\"relu\", kernel_regularizer=keras.regularizers.L2())(x)\n",
    "    x = layers.Dense(units=512, activation=\"relu\", kernel_regularizer=keras.regularizers.L2())(x)\n",
    "    x = layers.Dense(units=416, activation=\"relu\", kernel_regularizer=keras.regularizers.L2())(x)\n",
    "    x = layers.Dense(units=288, activation=\"tanh\", kernel_regularizer=keras.regularizers.L2())(x)\n",
    "    x = layers.Dense(units=224, activation=\"tanh\", kernel_regularizer=keras.regularizers.L2())(x)\n",
    "    \n",
    "    \n",
    "    output_layer = layers.Dense(1, activation=\"relu\")(x)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    # Modele compilation\n",
    "    model.compile(optimizer=adam, loss=loss, metrics=metric)\n",
    "    \n",
    "    \n",
    "    return model \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a12348-359e-4f6e-90f4-8c93ae93a893",
   "metadata": {},
   "source": [
    "### Instanciate main variables: callbacks, optimizer, loss , metrics, epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95496639-b377-4b0a-a3f8-4802fbdf342d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_NAME = \"1D-LeNet-like Tuning\"\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"best_model.keras\", save_best_only=True, monitor=\"val_accuracy\"),\n",
    "    keras.callbacks.ReduceLROnPlateau( monitor=\"val_accuracy\", factor=0.2, patience=10, min_lr=0.000001),\n",
    "    keras.callbacks.EarlyStopping( monitor=\"val_accuracy\", patience=8, verbose=1, mode=\"auto\", restore_best_weights=True, start_from_epoch=10)]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f02c7c3-c36e-46d4-b19f-9795466f5c9d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'Best 1D Le Net-like ' already exists. Creating a new version of this model...\n",
      "Created version '6' of model 'Best 1D Le Net-like '.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected `metrics` argument to be a list, tuple, or dict. Received instead: metrics=<keras.src.metrics.accuracy_metrics.BinaryAccuracy object at 0x132722fd0> of type <class 'keras.src.metrics.accuracy_metrics.BinaryAccuracy'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m model_uri \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mruns:/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mrun_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     16\u001b[0m mv \u001b[38;5;241m=\u001b[39m mlflow\u001b[38;5;241m.\u001b[39mregister_model(model_uri, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest 1D Le Net-like \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m hypermodel \u001b[38;5;241m=\u001b[39m build_model()\n\u001b[1;32m     19\u001b[0m keras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mplot_model(hypermodel,to_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel.png\u001b[39m\u001b[38;5;124m\"\u001b[39m, show_shapes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     21\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mlog_param(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseuil\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0.3\u001b[39m)\n",
      "Cell \u001b[0;32mIn[6], line 39\u001b[0m, in \u001b[0;36mbuild_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m model \u001b[38;5;241m=\u001b[39m Model(inputs\u001b[38;5;241m=\u001b[39minput_layer, outputs\u001b[38;5;241m=\u001b[39moutput_layer)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Modele compilation\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39madam, loss\u001b[38;5;241m=\u001b[39mloss, metrics\u001b[38;5;241m=\u001b[39mmetric)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/miniconda3/envs/Projet/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:123\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/Projet/lib/python3.11/site-packages/keras/src/trainers/compile_utils.py:131\u001b[0m, in \u001b[0;36mCompileMetrics.__init__\u001b[0;34m(self, metrics, weighted_metrics, name, output_names)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(name\u001b[38;5;241m=\u001b[39mname)\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m metrics \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(metrics, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mdict\u001b[39m)):\n\u001b[0;32m--> 131\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    132\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected `metrics` argument to be a list, tuple, or dict. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    133\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived instead: metrics=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(metrics)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    134\u001b[0m     )\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weighted_metrics \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    136\u001b[0m     weighted_metrics, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mdict\u001b[39m)\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    139\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected `weighted_metrics` argument to be a list, tuple, or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    140\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdict. Received instead: weighted_metrics=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mweighted_metrics\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    141\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(weighted_metrics)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    142\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Expected `metrics` argument to be a list, tuple, or dict. Received instead: metrics=<keras.src.metrics.accuracy_metrics.BinaryAccuracy object at 0x132722fd0> of type <class 'keras.src.metrics.accuracy_metrics.BinaryAccuracy'>"
     ]
    }
   ],
   "source": [
    "# Importer MLflow\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "\n",
    "try:\n",
    "    experiment_id = mlflow.create_experiment('Input Profil  ouput: Binary Malade/Normal')\n",
    "except:\n",
    "    experiment_name = 'Input Profil  ouput: Binary Malade/Normal'\n",
    "    current_experiment=dict(mlflow.get_experiment_by_name(experiment_name))\n",
    "    experiment_id=current_experiment['experiment_id']\n",
    "\n",
    "\n",
    "\n",
    "with mlflow.start_run(experiment_id =experiment_id) as run:\n",
    "    model_uri = f\"runs:/{run.info.run_id}\"\n",
    "    mv = mlflow.register_model(model_uri, \"Best 1D Le Net-like \")\n",
    "    \n",
    "    hypermodel = build_model()\n",
    "    keras.utils.plot_model(hypermodel,to_file=\"Model.png\", show_shapes=True)\n",
    "\n",
    "    mlflow.log_param(\"seuil\", 0.3)\n",
    "    mlflow.log_param(\"loss\", 'BinaryCrossentropy')\n",
    "    mlflow.log_param(\"learning rate\", 0.00011181404254174737)\n",
    "    mlflow.log_param(\"epoch\", 126)\n",
    " \n",
    "    \n",
    "    history = hypermodel.fit(x_train, y_train, epochs=126, validation_data=(x_val, y_val))\n",
    "\n",
    "    eval_result = hypermodel.evaluate(x_test, y_test)\n",
    "    y_pred = hypermodel.predict(x_test)\n",
    "    y_pred_class = np.apply_along_axis(lambda x: 1 if x>0.3 else 0, 1, y_pred)\n",
    "\n",
    "    confusion_m = metrics.confusion_matrix(y_test, y_pred_class)\n",
    "                \n",
    "    VN = confusion_m[0,0]\n",
    "    VP = confusion_m[1,1]\n",
    "    FN = confusion_m[1,0]\n",
    "    FP = confusion_m[0,1]\n",
    "\n",
    "    plot_history_metrics(history)\n",
    "    print('Justesse du jeu de test =', np.round((VP+VN)/(VP+VN+FP+FN)*100,2),'%')\n",
    "    print('Sensibilité =', np.round(VP*100/(VP+FN),2),'%')\n",
    "    print('Spécificité =', np.round(VN*100/(VN+FP),2),'%')\n",
    "\n",
    "    print('---------Matrice de confusition-----------------')\n",
    "    print('               pred:Malade     pred:Normal')\n",
    "    print('vrai Malade:      ',VP,'            ',FN)\n",
    "    print('vrai Normal       ',FP,'            ',VN)\n",
    "        \n",
    "    signature = mlflow.models.infer_signature(x_train, hypermodel.predict(x_train))\n",
    "    mlflow.keras.log_model(hypermodel, artifact_path=\"model\", signature=signature)\n",
    "    \n",
    "    mlflow.log_metric(\"Justesse\",(VP+VN)/(VP+VN+FP+FN))\n",
    "    mlflow.log_metric(\"VN\", VN)\n",
    "    mlflow.log_metric(\"VP\", VP)\n",
    "    mlflow.log_metric(\"FN\", FN)\n",
    "    mlflow.log_metric(\"FP\", FP)\n",
    "    mlflow.log_metric(\"Sensibilite\", VP/(VP+FN))\n",
    "    mlflow.log_metric(\"Specificite\", VN/(VN+FP))\n",
    "    mlflow.log_param(\"seuil\", 0.3)\n",
    "\n",
    "    mlflow.log_artifact(\"Training and Validation.png\")\n",
    "    mlflow.log_artifact(\"Model.png\")\n",
    "    mlflow.end_run()\n",
    "\n",
    "with open('./Model/last_exp3-1.pkl', 'wb') as pickle_file:\n",
    "    dump(all, pickle_file)\n",
    "    \n",
    "tf.keras.saving.save_model(hypermodel, './Model/last_exp3-1.keras')          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90608db4-36f8-49b9-b873-de5e40144afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(mlflow.models.infer_signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe722d5-dd28-490f-9de0-06965e2c7269",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd71215-ba01-4722-a110-7ddfd2d9058e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bd4d05-0480-4d1b-9e6f-d1b789c696f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc4e214-a00f-4c2f-8c0c-7827c4a9c9d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
