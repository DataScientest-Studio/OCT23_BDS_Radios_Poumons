{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet radiologie bootcamp DST : Etape 2, Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plan de preprocessing : \n",
    "* Ouvrir chaque image avec son masque associé\n",
    "* Convertir en Grayscale\n",
    "* Redimensionner les images à la taille des masques (256 * 256)\n",
    "* Appliquer les masques\n",
    "* Equilibrer le nouveau dataset\n",
    "* Séparer le dataset en ensemble d'entraînement (70%), de validation (15%) et de test (15%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import des bibliothèques\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import os, pathlib\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil #pour copier des fichiers vers les dossiers de preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etape 1 : création des images masquées et en échelles de gris\n",
    "* Ouvrir chaque image en grayscale en itérant sur les dossiers\n",
    "* Ouvrir le masque associé en grayscale\n",
    "* Resizer l'image en 256*256\n",
    "* Appliquer le masque\n",
    "* Enregistrer l'image dans un nouveau dossier\n",
    "\n",
    "### Pour le test du 21/12, un nouveau préprocessing ajouté avec \n",
    "* Application d'un filtre Gaussien\n",
    "* Application d'une égalisation d'histogramme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sous-fonction qui ouvre une image à partir du filepath, la convertit en Grayscale et la redimensionne en 256*256\n",
    "#En input : le filepath d'une image dans le dossier \"image\" => plutôt retravailler le masque\n",
    "def load_and_resize(file):\n",
    "    img = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (256, 256))\n",
    "    #Ajout pour test du 21/12 : fonctions de GaussianBlur et Histogram Equalization\n",
    "    img = cv2.equalizeHist(img)\n",
    "    img = cv2.GaussianBlur(img, (3,3), 0)\n",
    "    return img\n",
    "\n",
    "#Sous-fonction qui va chercher le masque et le convertit en Grayscale\n",
    "#En input : le filepath d'une image dans le dossier \"image\" qui est l'input de la fonction finale\n",
    "def load_mask(file):\n",
    "    mask_path = file.replace(\"images\",\"masks\")\n",
    "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "    return mask\n",
    "\n",
    "#Fonction qui applique le masque et enregistre l'image ainsi préprocessée dans un nouveau dossier\n",
    "#Input : image et masque (données d'origine), nom du fichier et chemin du dossier cible pour l'enregistrement\n",
    "def get_masked_imgs(sourceimg, nom_cible, dossier_cible):\n",
    "    img_resized = load_and_resize(sourceimg)\n",
    "    mask = load_mask(sourceimg)\n",
    "    img_masked = cv2.bitwise_and(img_resized, mask)\n",
    "    cv2.imwrite(os.path.join(dossier_cible, nom_cible), img_masked)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test sur 1 fichier\n",
    "fichier = \"../data/Sourcedata/COVID/images/COVID-1001.png\"\n",
    "nom_cible = os.path.split(fichier)[1]\n",
    "dossier_cible = \"../data/\"\n",
    "\n",
    "get_masked_imgs(fichier, nom_cible, dossier_cible)\n",
    "\n",
    "\n",
    "\n",
    "#print(img_resized.shape)\n",
    "#print(mask.shape)\n",
    "#plt.figure(figsize=(15, 5))\n",
    "#plt.subplot(131)\n",
    "#plt.imshow(img_resized, cmap = \"Greys_r\")\n",
    "#plt.subplot(132)\n",
    "#plt.imshow(mask, cmap = \"Greys_r\")\n",
    "#plt.subplot(133)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] Le chemin d’accès spécifié est introuvable: '/images/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m source_dir_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dossier_source,class_,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/images/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m target_dir_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dossier_cible, class_)\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource_dir_path\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[0;32m     12\u001b[0m     nom_cible \u001b[38;5;241m=\u001b[39m f\n\u001b[0;32m     13\u001b[0m     file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(source_dir_path, f)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] Le chemin d’accès spécifié est introuvable: '/images/'"
     ]
    }
   ],
   "source": [
    "#Définition des dossiers d'origine et cible, et lancement des fonctions => voir le script python dans SRC\n",
    "#class_list = [\"COVID\", \"Viral_Pneumonia\", \"Lung_Opacity\", \"Normal\"]\n",
    "class_list = [\"COVID\"]\n",
    "#dossiers_source_dict = {\"COVID\" : \"../data/COVID/images/\", \"NORMAL\" : \"../data/Normal/images/\", \"VIRAL_PNEUMONIA\" : \"../data/Viral Pneumonia/images/\", \"LUNG_OPACITY\" : \"../data/Lung_Opacity/images/\" }\n",
    "dossier_source = \"../data/Test/\"\n",
    "dossier_cible = \"../data/Preprocess_mask_intensity/\"\n",
    "\n",
    "#Itérer sur les dossiers pour récupérer les fichiers images\n",
    "for class_ in class_list:\n",
    "    source_dir_path = os.path.join(dossier_source,class_,\"/images/\")\n",
    "    target_dir_path = os.path.join(dossier_cible, class_)\n",
    "    for f in tqdm(os.listdir(source_dir_path)):\n",
    "        nom_cible = f\n",
    "        file = os.path.join(source_dir_path, f)\n",
    "        get_masked_imgs(file, nom_cible, target_dir_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etape 2 : Equilibrage des classes par sous-échantillonage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import de la base excel metadata\n",
    "meta_Covid = pd.read_excel(\"../data/COVID.metadata.xlsx\")\n",
    "meta_Covid.insert(loc = 0, column=\"CLASS\", value =  \"COVID\")\n",
    "meta_Normal = pd.read_excel(\"../data/Normal.metadata.xlsx\")\n",
    "meta_Normal.insert(loc = 0, column=\"CLASS\", value =  \"NORMAL\")\n",
    "meta_VPneu = pd.read_excel(\"../data/Viral Pneumonia.metadata.xlsx\")\n",
    "meta_VPneu.insert(loc = 0, column=\"CLASS\", value =  \"VIRAL_PNEUMONIA\")\n",
    "meta_LO = pd.read_excel(\"../data/Lung_Opacity.metadata.xlsx\")\n",
    "meta_LO.insert(loc = 0, column=\"CLASS\", value =  \"LUNG_OPACITY\")\n",
    "#Fusion des 4 metafichiers dans un dataframe\n",
    "metadata = pd.concat([meta_Covid, meta_LO, meta_Normal, meta_VPneu], axis = 0)\n",
    "#Enregistrement en csv\n",
    "metadata.to_csv(\"../data/metadata_compil.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21165\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "COVID              1345\n",
       "LUNG_OPACITY       1345\n",
       "NORMAL             1345\n",
       "VIRAL_PNEUMONIA    1345\n",
       "Name: CLASS, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Nb de valeurs par classe dans metadata\n",
    "print(len(metadata))\n",
    "metadata[\"CLASS\"].value_counts()\n",
    "\n",
    "#Utilisation d'un RandomUnderSampler pour équilibrer le dataset\n",
    "ru = RandomUnderSampler(random_state = 123, replacement = False)\n",
    "meta_ru, y_ru = ru.fit_resample(metadata, metadata[\"CLASS\"])\n",
    "meta_ru.head()\n",
    "meta_ru[\"CLASS\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5380"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_ru[\"CLASS\"].value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta Train :\n",
      " VIRAL_PNEUMONIA    942\n",
      "COVID              942\n",
      "NORMAL             941\n",
      "LUNG_OPACITY       941\n",
      "Name: CLASS, dtype: int64\n",
      "meta VAL :\n",
      " LUNG_OPACITY       202\n",
      "VIRAL_PNEUMONIA    202\n",
      "NORMAL             202\n",
      "COVID              201\n",
      "Name: CLASS, dtype: int64\n",
      "meta TEST :\n",
      " NORMAL             202\n",
      "COVID              202\n",
      "LUNG_OPACITY       202\n",
      "VIRAL_PNEUMONIA    201\n",
      "Name: CLASS, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TRAIN    3766\n",
       "VAL       807\n",
       "TEST      807\n",
       "Name: SET, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Sélection aléatoire et enregistrement des fichiers dans les dossiers TRAIN (70%), VALIDATE (15%), TEST (15%)\n",
    "# Séparation jeu de TRAIN à 70/30\n",
    "meta_TRAIN, meta_TESTVAL, y1, y2 = train_test_split(meta_ru, y_ru, test_size = 0.3, random_state = 123, stratify = y_ru)\n",
    "\n",
    "#Séparation du jeu de VALIDATION et TEST à 50/50\n",
    "meta_VAL, meta_TEST, y3, y4 = train_test_split(meta_TESTVAL, y2, test_size = 0.5, random_state = 123, stratify = y2)\n",
    "\n",
    "print(\"meta Train :\\n\", meta_TRAIN[\"CLASS\"].value_counts())\n",
    "print(\"meta VAL :\\n\", meta_VAL[\"CLASS\"].value_counts())\n",
    "print(\"meta TEST :\\n\", meta_TEST[\"CLASS\"].value_counts())\n",
    "meta_TRAIN.head()\n",
    "\n",
    "meta_TRAIN[\"SET\"] = \"TRAIN\"\n",
    "meta_VAL[\"SET\"] = \"VAL\"\n",
    "meta_TEST[\"SET\"] = \"TEST\"\n",
    "meta_dataset = pd.concat([meta_TRAIN, meta_VAL, meta_TEST], axis = 0)\n",
    "meta_dataset[\"SET\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etape 3 : enregistrement des 3 datasets dans 3 sous-dossiers TRAIN, VAL, TEST du dossier PREPROCESSING_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CLASS</th>\n",
       "      <th>FILE NAME</th>\n",
       "      <th>FORMAT</th>\n",
       "      <th>SIZE</th>\n",
       "      <th>URL</th>\n",
       "      <th>SET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4080</th>\n",
       "      <td>VIRAL_PNEUMONIA</td>\n",
       "      <td>Viral Pneumonia-46</td>\n",
       "      <td>PNG</td>\n",
       "      <td>256*256</td>\n",
       "      <td>https://www.kaggle.com/paultimothymooney/chest...</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106</th>\n",
       "      <td>COVID</td>\n",
       "      <td>COVID-2461</td>\n",
       "      <td>PNG</td>\n",
       "      <td>256*256</td>\n",
       "      <td>https://bimcv.cipf.es/bimcv-projects/bimcv-cov...</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4244</th>\n",
       "      <td>VIRAL_PNEUMONIA</td>\n",
       "      <td>Viral Pneumonia-210</td>\n",
       "      <td>PNG</td>\n",
       "      <td>256*256</td>\n",
       "      <td>https://www.kaggle.com/paultimothymooney/chest...</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5306</th>\n",
       "      <td>VIRAL_PNEUMONIA</td>\n",
       "      <td>Viral Pneumonia-1272</td>\n",
       "      <td>PNG</td>\n",
       "      <td>256*256</td>\n",
       "      <td>https://www.kaggle.com/paultimothymooney/chest...</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1058</th>\n",
       "      <td>COVID</td>\n",
       "      <td>COVID-1693</td>\n",
       "      <td>PNG</td>\n",
       "      <td>256*256</td>\n",
       "      <td>https://bimcv.cipf.es/bimcv-projects/bimcv-cov...</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                CLASS             FILE NAME FORMAT     SIZE  \\\n",
       "4080  VIRAL_PNEUMONIA    Viral Pneumonia-46    PNG  256*256   \n",
       "1106            COVID            COVID-2461    PNG  256*256   \n",
       "4244  VIRAL_PNEUMONIA   Viral Pneumonia-210    PNG  256*256   \n",
       "5306  VIRAL_PNEUMONIA  Viral Pneumonia-1272    PNG  256*256   \n",
       "1058            COVID            COVID-1693    PNG  256*256   \n",
       "\n",
       "                                                    URL    SET  \n",
       "4080  https://www.kaggle.com/paultimothymooney/chest...  TRAIN  \n",
       "1106  https://bimcv.cipf.es/bimcv-projects/bimcv-cov...  TRAIN  \n",
       "4244  https://www.kaggle.com/paultimothymooney/chest...  TRAIN  \n",
       "5306  https://www.kaggle.com/paultimothymooney/chest...  TRAIN  \n",
       "1058  https://bimcv.cipf.es/bimcv-projects/bimcv-cov...  TRAIN  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5380it [01:45, 50.92it/s]\n"
     ]
    }
   ],
   "source": [
    "dossier_source = \"..\\\\data\\\\Preprocessing_1\"\n",
    "dossiers_cibles_dict = {\"TRAIN\" : \"..\\\\data\\\\Preprocessing_2\\Train\", \"VAL\" : \"..\\\\data\\\\Preprocessing_2\\Train\", \"TEST\" : \"..\\\\data\\\\Preprocessing_2\\Train\"}\n",
    "\n",
    "#Fonction pour copier les fichiers dans le dossier cible\n",
    "def copy_to_folder(filename, source_folder, target_folder):\n",
    "    filename = filename + \".png\"\n",
    "    #chemin d'accès au fichier soruce\n",
    "    src = os.path.join(source_folder, filename)\n",
    "    #chemin d'accès du fichier copié\n",
    "    dst = os.path.join(target_folder, filename)\n",
    "    #copie\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "#Itération sur les noms de fichiers retenus par le TRAIN TEST SPLIT\n",
    "for index, row in tqdm(meta_dataset.iterrows()):\n",
    "    dossier_cible = dossiers_cibles_dict[row[\"SET\"]]\n",
    "    copy_to_folder(row[\"FILE NAME\"], dossier_source, dossier_cible)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création du jeu de donnée préprocessé et équilibré"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Principe : \n",
    "- à partir du jeu d'images préprocessé (Préprocessing_1)\n",
    "- On part du nombre minimal d'échantillons par classe : 1345 (5380 images au total)\n",
    "- On met de côté 15% des images pour le test (pas fourni au modèle) : 800 (200 par classe), avec équilibre des classes\n",
    "- On copie 4 jeux :\n",
    "    - 400 images (100*4)\n",
    "    - 1000 images (250 * 4)\n",
    "    - 2000 images (500 * 4)\n",
    "    - 4000 images (1000 * 4) \n",
    "    - Toutes les images : 4576 (1144/classe), arrondi\n",
    "\n",
    "Noms : Train_set_400, Train_set_1000, Train_set_2000, Train_set_4000, Train_set_4576, Test_set_800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NORMAL             10192\n",
       "LUNG_OPACITY        6012\n",
       "COVID               3616\n",
       "VIRAL_PNEUMONIA     1345\n",
       "Name: CLASS, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Nombre d'échantillons de la classe la moins représentée : 1345\n",
    "metadata = pd.read_csv(\"../data/metadata_compil.csv\")\n",
    "metadata.head()\n",
    "metadata[\"CLASS\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[WinError 183] Impossible de créer un fichier déjà existant: 'c:\\\\Users\\\\thiba\\\\Documents\\\\Projets data\\\\data\\\\Train_set_400'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\thiba\\Documents\\Projets data\\OCT23_BDS_Radios_Poumons\\notebooks\\2.0 Thibaut Preprocessing.ipynb Cell 19\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/thiba/Documents/Projets%20data/OCT23_BDS_Radios_Poumons/notebooks/2.0%20Thibaut%20Preprocessing.ipynb#X30sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m dossier \u001b[39min\u001b[39;00m dossiers_a_creer:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/thiba/Documents/Projets%20data/OCT23_BDS_Radios_Poumons/notebooks/2.0%20Thibaut%20Preprocessing.ipynb#X30sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     new_dossier \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mabspath(dossier_racine), dossier)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/thiba/Documents/Projets%20data/OCT23_BDS_Radios_Poumons/notebooks/2.0%20Thibaut%20Preprocessing.ipynb#X30sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     os\u001b[39m.\u001b[39;49mmakedirs(new_dossier)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/thiba/Documents/Projets%20data/OCT23_BDS_Radios_Poumons/notebooks/2.0%20Thibaut%20Preprocessing.ipynb#X30sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mfor\u001b[39;00m sousdossier \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mNORMAL\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mCOVID\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mLUNG OPACITY\u001b[39m\u001b[39m\"\u001b[39m , \u001b[39m\"\u001b[39m\u001b[39mVIRAL PNEUMONIA\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/thiba/Documents/Projets%20data/OCT23_BDS_Radios_Poumons/notebooks/2.0%20Thibaut%20Preprocessing.ipynb#X30sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         new_sousdossier \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(new_dossier, sousdossier)\n",
      "File \u001b[1;32mc:\\Users\\thiba\\anaconda3\\lib\\os.py:225\u001b[0m, in \u001b[0;36mmakedirs\u001b[1;34m(name, mode, exist_ok)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    224\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 225\u001b[0m     mkdir(name, mode)\n\u001b[0;32m    226\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n\u001b[0;32m    227\u001b[0m     \u001b[39m# Cannot rely on checking for EEXIST, since the operating system\u001b[39;00m\n\u001b[0;32m    228\u001b[0m     \u001b[39m# could give priority to other errors like EACCES or EROFS\u001b[39;00m\n\u001b[0;32m    229\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m exist_ok \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m path\u001b[39m.\u001b[39misdir(name):\n",
      "\u001b[1;31mFileExistsError\u001b[0m: [WinError 183] Impossible de créer un fichier déjà existant: 'c:\\\\Users\\\\thiba\\\\Documents\\\\Projets data\\\\data\\\\Train_set_400'"
     ]
    }
   ],
   "source": [
    "#Créer les dossiers cibles #a marché mais ils n'apparaissent pas dans Windows... a la mano !\n",
    "dossier_racine = \"../../data/\"\n",
    "dossiers_a_creer = [\"Train_set_400\", \"Train_set_1000\", \"Train_set_2000\", \"Train_set_4000\", \"Train_set_4580\", \"Test_set_800\"]\n",
    "for dossier in dossiers_a_creer:\n",
    "    new_dossier = os.path.join(os.path.abspath(dossier_racine), dossier)\n",
    "    os.makedirs(new_dossier)\n",
    "    for sousdossier in [\"NORMAL\", \"COVID\", \"LUNG OPACITY\" , \"VIRAL PNEUMONIA\"]:\n",
    "        new_sousdossier = os.path.join(new_dossier, sousdossier)\n",
    "        os.makedirs(new_sousdossier)\n",
    "print(os.listdir(dossier_racine))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Preprocessing_1', 'Test_set_800', 'Train_set_1000', 'Train_set_2000', 'Train_set_400', 'Train_set_4000', 'Train_set_4580']\n",
      "['COVID', 'LUNG OPACITY', 'NORMAL', 'VIRAL PNEUMONIA']\n"
     ]
    }
   ],
   "source": [
    "#On vérifie\n",
    "print(os.listdir(dossier_racine))\n",
    "print(os.listdir(os.path.join(dossier_racine,\"Train_set_1000\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#à partir du total 1345/classe\n",
    "#On copie 4 jeux :\n",
    "#    - 400 images (100*4)\n",
    "#    - 1000 images (250 * 4)\n",
    "#    - 2000 images (500 * 4)\n",
    "#    - 4000 images (1000 * 4) \n",
    "#    - Toutes les images : 4580 (1145/classe)\n",
    "\n",
    "\n",
    "\n",
    "#Nécessite de calculer l'équilibre des classes en amont\n",
    "def extract_subset(dossier_source, dossier_cible_train, dossier_cible_test, nb_img_train_par_classe:int, nb_img_test_par_classe:int):\n",
    "    #Parcourir les dossiers du dataset préprocessé\n",
    "    for c in os.listdir(dossier_source):\n",
    "        #parcourir chaque classe \n",
    "        classe = os.path.join(dossier_source, c)\n",
    "        #Créer un array randomisé et séparer en TRAIN/TEST d'après le pct de split\n",
    "        #boucle sur un array randomisé entre 1 et le nombre d'images total à extraire pour chaque classe\n",
    "        nb_total_img_a_extraire = nb_img_train_par_classe + nb_img_test_par_classe\n",
    "        random_array = np.random.choice(os.listdir(classe), nb_total_img_a_extraire, replace = False)\n",
    "        #Extraction du jeu de TEST en prenant les X premiers fichiers randomisés\n",
    "        for file in tqdm(random_array[:nb_img_test_par_classe]):\n",
    "            #chemin d'accès au fichier soruce\n",
    "            src = os.path.join(classe, file)\n",
    "            #chemin d'accès du fichier copié\n",
    "            dst = os.path.join(dossier_cible_test, c, file)\n",
    "            #copie\n",
    "            shutil.copyfile(src, dst)\n",
    "        #Extraction du jeu de TRAIN\n",
    "        for file in tqdm(random_array[nb_img_test_par_classe:]):\n",
    "            #chemin d'accès au fichier soruce\n",
    "            src = os.path.join(classe, file)\n",
    "            #chemin d'accès du fichier copié\n",
    "            dst = os.path.join(dossier_cible_train, c, file)\n",
    "            #copie\n",
    "            shutil.copyfile(src, dst)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1004.14it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 450.85it/s]\n"
     ]
    }
   ],
   "source": [
    "#On fait tourner la fonction pour tester\n",
    "dossier_source = \"../../../Projets data/Projet-radio-DST_TG/data/test2/\" \n",
    "dossier_cible_train = \"../../../Projets data/Projet-radio-DST_TG/data/test3/Train\"\n",
    "dossier_cible_test = \"../../../Projets data/Projet-radio-DST_TG/data/test3/Test\"\n",
    "extract_subset(dossier_source, dossier_cible_train, dossier_cible_test, 2, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 41/201 [00:00<00:00, 368.11it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 201/201 [00:00<00:00, 358.80it/s]\n",
      "100%|██████████| 1144/1144 [00:02<00:00, 396.86it/s]\n",
      "100%|██████████| 201/201 [00:00<00:00, 419.73it/s]\n",
      "100%|██████████| 1144/1144 [00:03<00:00, 368.38it/s]\n",
      "100%|██████████| 201/201 [00:00<00:00, 392.35it/s]\n",
      "100%|██████████| 1144/1144 [00:03<00:00, 362.27it/s]\n",
      "100%|██████████| 201/201 [00:00<00:00, 410.08it/s]\n",
      "100%|██████████| 1144/1144 [00:03<00:00, 373.29it/s]\n"
     ]
    }
   ],
   "source": [
    "# D'abord on isole un jeu de test (15% = 201 imgs/classe) et un set d'entraînement \"MAX\" à partir du jeu d'images préprocessé  \n",
    "dossier_source = \"../data/Preprocessing_1/\"\n",
    "dossier_cible_train = \"../data/Train_set_4576/\"\n",
    "dossier_cible_test = \"../data/Test_set_800/\"\n",
    "extract_subset(dossier_source, dossier_cible_train, dossier_cible_test, 1144, 201)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 103.97it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 112.46it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 106.99it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 96.53it/s]\n"
     ]
    }
   ],
   "source": [
    "#Ensuite on créée des jeux de test réduits à partir du jeu complet pour tester les différentes test sizes\n",
    "#400\n",
    "for i in [400]:\n",
    "    dossier_source = \"../data/Train_set_4576/\"\n",
    "    dossier_cible_train = \"../data/Train_set_\" + str(i)\n",
    "    dossier_cible_test = \"../data/\"\n",
    "    extract_subset(dossier_source, dossier_cible_train, dossier_cible_test, i//4, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 250/250 [00:02<00:00, 98.24it/s] \n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 250/250 [00:03<00:00, 82.15it/s] \n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 250/250 [00:02<00:00, 104.04it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 250/250 [00:02<00:00, 90.00it/s] \n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 500/500 [00:06<00:00, 80.89it/s] \n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 500/500 [00:07<00:00, 69.17it/s] \n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 500/500 [00:04<00:00, 108.96it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 500/500 [00:04<00:00, 110.39it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 1000/1000 [00:05<00:00, 181.36it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 1000/1000 [00:05<00:00, 177.04it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 1000/1000 [00:05<00:00, 178.32it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 1000/1000 [00:06<00:00, 148.18it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in [1000, 2000, 4000]:\n",
    "    dossier_source = \"../data/Train_set_4576/\"\n",
    "    dossier_cible_train = \"../data/Train_set_\" + str(i)\n",
    "    dossier_cible_test = \"../data/\"\n",
    "    extract_subset(dossier_source, dossier_cible_train, dossier_cible_test, i//4, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tous les jeux sont bons pour les prochains modèms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nouvelle extraction d'un jeu à 2O OOO images suite aux tests de modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Répertoire  :  ..\\data\\Preprocessing_1\n",
      "Nombre images set  21165\n",
      "Répertoire  :  ..\\data\\Preprocessing_1\\COVID\n",
      "Nombre images set  3616\n",
      "Répertoire  :  ..\\data\\Preprocessing_1\\Lung_Opacity\n",
      "Nombre images set  6012\n",
      "Répertoire  :  ..\\data\\Preprocessing_1\\Normal\n",
      "Nombre images set  10192\n",
      "Répertoire  :  ..\\data\\Preprocessing_1\\Viral_Pneumonia\n",
      "Nombre images set  1345\n"
     ]
    }
   ],
   "source": [
    "#Paramètres\n",
    "dataset_preprocess_path = \"../data/Preprocessing_1/\"\n",
    "dataset_commun_path = \"../data/Dataset_commun/\"\n",
    "target_folder = \"../data/Dataset_commun_augmenté/\"\n",
    "\n",
    "dataset_preprocess_dir = pathlib.Path(dataset_preprocess_path).with_suffix('')\n",
    "dataset_commun_dir = pathlib.Path(dataset_commun_path).with_suffix('')\n",
    "target_dir = pathlib.Path(target_folder).with_suffix('')\n",
    "class_dir = list(dataset_preprocess_dir.glob('*'))\n",
    "\n",
    "# Vérification nombre d'images dans le set de preprocess\n",
    "print (\"Répertoire  : \", dataset_preprocess_dir)\n",
    "train_set_image_count = len(list(dataset_preprocess_dir.glob('*/*.png')))\n",
    "print(\"Nombre images set \", train_set_image_count)\n",
    "\n",
    "# Vérification nombre d'images par classe\n",
    "for class_ in class_dir:\n",
    "    print (\"Répertoire  : \", class_)\n",
    "    image_count = len(list(class_.glob(\"*.png\")))\n",
    "    print(\"Nombre images set \", image_count)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb images par classe TRAIN :  2893  \n",
      "Nb images par classe TEST :  723\n"
     ]
    }
   ],
   "source": [
    "#Je choisis de créer un dataset aligné sur la classe COVID : 3616 images par classe répartie aléatoirement entre Train et Test avec 20% test.\n",
    "#La classe Viral Pneumonia est celle qui obtient les meilleurs scores de classification, on peut donc copier aléatoirement des images pour compléter le jeu sans risquer de dégrader la perf sur cette classe\n",
    "# Définir le nombre d'images à piocher dans le set complet pour équilibrer les classes\n",
    "nb_img_par_classe = 3616\n",
    "\n",
    "test_ratio = 0.2\n",
    "nb_img_cible_test = round(nb_img_par_classe * test_ratio)\n",
    "nb_img_cible_train = nb_img_par_classe - nb_img_cible_test\n",
    "print(\"Nb images par classe TRAIN : \", nb_img_cible_train, \" \\nNb images par classe TEST : \", nb_img_cible_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['COVID', 'Lung_Opacity', 'Normal', 'Viral_Pneumonia']\n"
     ]
    }
   ],
   "source": [
    "#Récupérer les noms des classes\n",
    "class_list = [str(i).rsplit(\"\\\\\", 1)[1] for i in class_dir] \n",
    "print(class_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Approche choisie : augmenter le jeu de données baseline existant : \n",
    "# - Piocher des images en plus dans le dataset préprocessé initial jusqu'à atteindre 3616\n",
    "# - Pour Viral Pneumonia, copier des images des datasets existants \n",
    "#ceci afin d'éviter de mélanger des images Train et Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create class directories : OK\n",
    "\n",
    "for label in class_list:\n",
    "    for subfolder in [\"Train/\", \"Test/\"]:\n",
    "        ds_folder = target_folder + subfolder + label\n",
    "        if not os.path.exists(ds_folder):\n",
    "            os.mkdir(ds_folder)\n",
    "\n",
    "# set the destination target\n",
    "#label_df['path'] = label_df['class'].astype(str) + os.path.sep + label_df['image']\n",
    "\n",
    "# copy or move files\n",
    "#for _, row in label_df.iterrows():\n",
    "    # shutil.copy(row['image'], row['path'])\n",
    "#    shutil.move(row['image'], row['path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COVID\n",
      "Nombre d'images de la classe dans le set préprocessé :  3616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 122/723 [00:00<00:01, 571.24it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 723/723 [00:01<00:00, 406.35it/s]\n",
      "100%|██████████| 2893/2893 [00:07<00:00, 386.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lung_Opacity\n",
      "Nombre d'images de la classe dans le set préprocessé :  6012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 723/723 [00:07<00:00, 102.86it/s]\n",
      "100%|██████████| 2893/2893 [00:22<00:00, 127.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal\n",
      "Nombre d'images de la classe dans le set préprocessé :  10192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 723/723 [00:09<00:00, 78.60it/s]\n",
      "100%|██████████| 2893/2893 [00:36<00:00, 78.27it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Viral_Pneumonia\n",
      "Nombre d'images de la classe dans le set préprocessé :  1345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 723/723 [00:08<00:00, 86.25it/s] \n",
      "100%|██████████| 622/622 [00:07<00:00, 82.29it/s] \n"
     ]
    }
   ],
   "source": [
    "#Fonction pour itérer sur les classes et copier le nombre d'images voulues dans un dossier cible avec un split entre Train et Test \n",
    "for class_ in class_dir:\n",
    "\n",
    "    #extraire le nom de la classe\n",
    "    class_name = str(class_).rsplit(\"\\\\\", 1)[1]\n",
    "    print(class_name) \n",
    "\n",
    "    #Définir le dossier cible\n",
    "    target_train_folder = pathlib.Path(target_folder + \"Train/\" + class_name).with_suffix('')\n",
    "    target_test_folder = pathlib.Path(target_folder + \"Test/\" + class_name).with_suffix('')\n",
    "\n",
    "    #Extraire la liste des images dans le set source préprocessé \n",
    "    img_path_list = list(class_.glob('*.png'))\n",
    "    print(\"Nombre d'images de la classe dans le set préprocessé : \", len(img_path_list)) \n",
    "    #Extraire les noms des images depuis les \"path\"\n",
    "    img_names_list_source = [str(i).rsplit(\"\\\\\", 1)[1] for i in img_path_list]\n",
    "\n",
    "\n",
    "    #Initialisation d'un array sans remise, taille = nombre d'images cible\n",
    "    random_array = np.random.choice(img_names_list_source, min(nb_img_par_classe,len(img_path_list)) , replace = False)\n",
    "\n",
    "    #Extraction du jeu de TEST en prenant les 20% premières images de l'array randomisé\n",
    "    test_size = round(nb_img_par_classe * test_ratio)\n",
    "    for file in tqdm(random_array[:test_size]):\n",
    "        #chemin d'accès au fichier soruce\n",
    "        src = os.path.join(class_, file)\n",
    "        #chemin d'accès du fichier copié\n",
    "        dst = os.path.join(target_test_folder, file)\n",
    "        #copie\n",
    "        shutil.copyfile(src, dst)\n",
    "\n",
    "    #Extraction du jeu de TRAIN\n",
    "    for file in tqdm(random_array[test_size:]):\n",
    "        #chemin d'accès au fichier soruce\n",
    "        src = os.path.join(class_, file)\n",
    "        #chemin d'accès du fichier copié\n",
    "        dst = os.path.join(target_train_folder, file)\n",
    "        #copie\n",
    "        shutil.copyfile(src, dst)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "#Itérer sur les classes\n",
    "\n",
    "\n",
    "    #Extraire la liste des images dans le dossier source, afficher le nombvre\n",
    "\n",
    "\n",
    " #   train_dir = \n",
    " #   train_dir_list = \n",
    " #   test_dir = \n",
    " #   test_dir_list =\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On accepte moins d'images dans le jeu d'entraînement Viral_Pneumonia, car la perf est déjà bonne"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
